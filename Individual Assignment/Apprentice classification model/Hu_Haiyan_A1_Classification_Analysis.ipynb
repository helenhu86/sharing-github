{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"mark\">\n",
    "Part I: FEATURE ENGINEERING AND MODEL PREPARATION</div><i class=\"fa fa-lightbulb-o \"></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP 1- importing packages and loading data.\n",
    "\n",
    "# importing libraries\n",
    "#import pandas as pd # data science essentials\n",
    "#import matplotlib.pyplot as plt # essential graphical output\n",
    "#import seaborn as sns # enhanced graphical output\n",
    "#import numpy as np\n",
    "#import statsmodels.formula.api as smf\n",
    "\n",
    "# setting pandas print options\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "#pd.set_option('display.max_columns', 500)\n",
    "#pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "# specifying file name\n",
    "#file = './Apprentice_Chef_Dataset.xlsx'\n",
    "\n",
    "\n",
    "# reading the file into Python\n",
    "#chef = pd.read_excel(io=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# dealing with gender\n",
    "#import random as rand \n",
    "#import gender_guesser.detector as gender\n",
    "#rand.seed(a = 327)\n",
    "\n",
    "#placeholder_lst=[]\n",
    "#for name in chef[\"FIRST_NAME\"]: \n",
    "#    guess = gender.Detector().get_gender(name)\n",
    "    #print(guess) \n",
    " #   placeholder_lst.append(guess)#print(guess) placeholder_lst.append(guess)\n",
    "    \n",
    "#chef['gender'] = pd.Series(placeholder_lst) # store this, so it won't run again. chef['gender_guess'] = gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#chef.to_excel('./Apprentice_Chef_Dataset.xlsx',\n",
    "#                 index = False) # save gender to this excel after running gender guesser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the above code to create a new column 'gender'. \n",
    "The original excel 'Apprentice_Chef_Dataset.xlsx' is added with a new column 'gender'.\n",
    "Please use my zip file. Thanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# importing libraries\n",
    "import pandas as pd # data science essentials\n",
    "import matplotlib.pyplot as plt # essential graphical output\n",
    "import seaborn as sns # enhanced graphical output\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "# specifying file name. a new column gender is added to this dataset\n",
    "file = './Apprentice_Chef_Dataset.xlsx'\n",
    "\n",
    "\n",
    "# reading the file into Python\n",
    "chef = pd.read_excel(io=file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saathos</td>\n",
       "      <td>unitedhealth.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alysanne.osgrey</td>\n",
       "      <td>ge.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edwyd.fossoway</td>\n",
       "      <td>jnj.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eleyna.westerling</td>\n",
       "      <td>ge.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>elyn.norridge</td>\n",
       "      <td>jnj.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>obara.sand</td>\n",
       "      <td>yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>quentyn.blackwood</td>\n",
       "      <td>yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>rhonda.rowan</td>\n",
       "      <td>gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>turnip</td>\n",
       "      <td>yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>tommard.heddle</td>\n",
       "      <td>merck.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1946 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0                 1\n",
       "0               saathos  unitedhealth.com\n",
       "1       alysanne.osgrey            ge.org\n",
       "2        edwyd.fossoway           jnj.com\n",
       "3     eleyna.westerling            ge.org\n",
       "4         elyn.norridge           jnj.com\n",
       "...                 ...               ...\n",
       "1941         obara.sand         yahoo.com\n",
       "1942  quentyn.blackwood         yahoo.com\n",
       "1943       rhonda.rowan         gmail.com\n",
       "1944             turnip         yahoo.com\n",
       "1945     tommard.heddle         merck.com\n",
       "\n",
       "[1946 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature engineering emails.\n",
    "\n",
    "#Using EMAIL to get the domain out and then catogorize the email domains\n",
    "# step a\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in chef.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "    split_email = chef.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "\n",
    "# converting placeholder_lst into a DataFrame \n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "# displaying the results\n",
    "email_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unitedhealth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ge.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jnj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ge.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jnj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>yahoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>yahoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>gmail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>yahoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>merck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1946 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "0     unitedhealth\n",
       "1           ge.org\n",
       "2              jnj\n",
       "3           ge.org\n",
       "4              jnj\n",
       "...            ...\n",
       "1941         yahoo\n",
       "1942         yahoo\n",
       "1943         gmail\n",
       "1944         yahoo\n",
       "1945         merck\n",
       "\n",
       "[1946 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step b: remove \".com\" from domains\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in email_df.iterrows():\n",
    "    \n",
    "    \n",
    "    replace_email = email_df.iloc[index, 1].replace('.com','')\n",
    "\n",
    "    placeholder_lst.append(replace_email)\n",
    "    \n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "# displaying the results\n",
    "email_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>EMAIL_domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unitedhealth</td>\n",
       "      <td>unitedhealth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ge</td>\n",
       "      <td>ge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jnj</td>\n",
       "      <td>jnj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ge</td>\n",
       "      <td>ge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jnj</td>\n",
       "      <td>jnj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0  EMAIL_domain\n",
       "0  unitedhealth  unitedhealth\n",
       "1            ge            ge\n",
       "2           jnj           jnj\n",
       "3            ge            ge\n",
       "4           jnj           jnj"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step c, removing \".org\" in domains\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in email_df.iterrows():\n",
    "    \n",
    "    \n",
    "    replace_email = email_df.iloc[index, 0].replace('.org','')\n",
    "  \n",
    "    placeholder_lst.append(replace_email)\n",
    "    \n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "# displaying the results\n",
    "\n",
    "email_df\n",
    "email_df['EMAIL_domain']=email_df.iloc[:,0]\n",
    "email_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP d: concatenating with original DataFrame\n",
    "\n",
    "# safety measure in case of multiple concatenations\n",
    "#chef = pd.read_excel(file)\n",
    "\n",
    "\n",
    "# renaming column to concatenate\n",
    "email_df.columns = [\"0\" , \"EMAIL_domain\"]\n",
    "\n",
    "\n",
    "# concatenating personal_email_domain with friends DataFrame\n",
    "chef = pd.concat([chef, email_df[\"EMAIL_domain\"]],\n",
    "                   axis = 1)\n",
    "\n",
    "\n",
    "# printing value counts of personal_email_domain\n",
    "#chef.loc[: ,'EMAIL_domain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "personal_email    861\n",
       "business_email    696\n",
       "junk_email        389\n",
       "Name: DOMAIN_group, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP e: Categorize email domains to personal,business, and junk\n",
    "personal_email_domains = ['gmail', 'protonmail','yahoo']\n",
    "business_email_domains  = ['homedepot','intel','unitedtech','cisco','goldmansacs',\n",
    "                              'jpmorgan','visa','pfizer','disney','walmart','unitedhealth',\n",
    "'boeing','caterpillar','verizon','pg','dupont','ibm','chevron','microsoft', \n",
    "'travelers','exxon','amex','cocacola','mcdonalds','merck','jnj','apple','nike',          \n",
    "'ge','mmm']\n",
    "junk_email_domains = ['me','aol','hotmail','live','msn','passport']\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "\n",
    "# looping to group observations by domain type\n",
    "for domain in chef['EMAIL_domain']:\n",
    "    \n",
    "    if domain in personal_email_domains:\n",
    "        placeholder_lst.append('personal_email')\n",
    "        \n",
    "\n",
    "    elif domain in business_email_domains:\n",
    "        placeholder_lst.append('business_email')\n",
    "\n",
    "\n",
    "    else:\n",
    "        placeholder_lst.append('junk_email')\n",
    "\n",
    "\n",
    "# concatenating with original DataFrame\n",
    "chef['DOMAIN_group'] = pd.Series(placeholder_lst)\n",
    "\n",
    "\n",
    "# checking results\n",
    "chef['DOMAIN_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP f, Getting dummy variables from catogory variable\"EMAIL_domain\"\n",
    "# one hot encoding categorical variables\n",
    "one_hot_email       = pd.get_dummies(chef['DOMAIN_group'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# joining codings together\n",
    "chef = chef.join([one_hot_email])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Ordinary meal set\n",
    "chef['ordinary_meals_ordered']= chef['TOTAL_MEALS_ORDERED'] - chef['UNIQUE_MEALS_PURCH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# total logins\n",
    "chef['total_logins'] = chef['MOBILE_LOGINS'] + chef['PC_LOGINS']\n",
    "\n",
    "#total time visiting\n",
    "chef['total_time_visiting']=chef['AVG_TIME_PER_SITE_VISIT']*(chef['MOBILE_LOGINS']+chef['PC_LOGINS'])\n",
    "\n",
    "#total clicks\n",
    "chef['total_clicks'] =chef['AVG_CLICKS_PER_VISIT']*(chef['MOBILE_LOGINS']+chef['PC_LOGINS'])\n",
    "\n",
    "#avg revenue per meal\n",
    "chef['avg_revenue_per_meal'] = chef['REVENUE']/chef['TOTAL_MEALS_ORDERED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# according to the case. regular meal set ranges from $10- $23. wine costs from $7 to $25.\n",
    "# make an assumption: if avg_revenue_per_meal greater than $40, client has a hobby to order alcohol.\n",
    "\n",
    "chef['like_alcohol'] = 0\n",
    "\n",
    "for index, value in chef.iterrows():\n",
    "    \n",
    "    \n",
    "    if chef.loc[index, 'avg_revenue_per_meal'] > 40:\n",
    "        chef.loc[index, 'like_alcohol'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# total order times per customer per year\n",
    "chef['total_order_times'] = chef['TOTAL_MEALS_ORDERED']/chef['LARGEST_ORDER_SIZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#log transforming\n",
    "\n",
    "chef['log_REVENUE'] = np.log10(chef['REVENUE'])\n",
    "chef['log_AVG_TIME_PER_SITE_VISIT'] = np.log10(chef['AVG_TIME_PER_SITE_VISIT'])\n",
    "chef['log_AVG_PREP_VID_TIME']=np.log10(chef['AVG_PREP_VID_TIME'])\n",
    "chef['log_TOTAL_MEALS_ORDERED'] = np.log10(chef['TOTAL_MEALS_ORDERED'])\n",
    "chef['log_UNIQUE_MEALS_PURCH'] = np.log10(chef.loc[:, 'UNIQUE_MEALS_PURCH'])\n",
    "chef[\"log_CONTACTS_W_CUSTOMER_SERVICE\"]=np.log10(chef.loc[:,\"CONTACTS_W_CUSTOMER_SERVICE\"])\n",
    "chef['log_PRODUCT_CATEGORIES_VIEWED']=np.log10(chef.loc[:,\"PRODUCT_CATEGORIES_VIEWED\"])\n",
    "chef[\"log_AVG_CLICKS_PER_VISIT\"]=np.log10(chef.loc[:,\"AVG_CLICKS_PER_VISIT\"])\n",
    "chef['log_total_order_times']=np.log10(chef.loc[:,\"total_order_times\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# creating binary if counts of 0s is greater than 100.\n",
    "chef['has_WEEKLY_PLAN']   = 0\n",
    "chef['has_VIEWED_PHOTOS'] = 0\n",
    "chef['has_EARLY_DELIVERIES'] = 0\n",
    "chef['has_LATE_DELIVERIES'] = 0\n",
    "chef['has_MASTER_CLASSES_ATTENDED'] = 0\n",
    "chef['has_CANCELLATIONS_BEFORE_NOON'] = 0\n",
    "chef['has_CANCELLATIONS_AFTER_NOON'] = 0\n",
    "chef['has_REFRIGERATED_LOCKER'] = 0\n",
    "chef['has_PACKAGE_LOCKER'] = 0\n",
    "\n",
    "#rating 1,2,3,4,5\n",
    "chef['MEDIAN_MEAL_RATING_1'] = 0\n",
    "chef['MEDIAN_MEAL_RATING_2'] = 0\n",
    "chef['MEDIAN_MEAL_RATING_3'] = 0\n",
    "chef['MEDIAN_MEAL_RATING_4'] = 0\n",
    "chef['MEDIAN_MEAL_RATING_5'] = 0\n",
    "\n",
    "#flagging missing family name\n",
    "chef['m_FAMILY_NAME']   = 0\n",
    "\n",
    "#creating dummies from gender\n",
    "chef['FEMALE'] = 0\n",
    "chef['MALE'] = 0\n",
    "chef['UNKNOWN_GENDER'] = 0\n",
    "\n",
    "\n",
    "\n",
    "for index, value in chef.iterrows():\n",
    "    \n",
    "    # has weekly plan\n",
    "    if chef.loc[index, 'WEEKLY_PLAN'] > 0:\n",
    "        chef.loc[index, 'has_WEEKLY_PLAN'] = 1\n",
    "\n",
    "    #viewed photos or not\n",
    "    if chef.loc[index, 'TOTAL_PHOTOS_VIEWED'] > 0:\n",
    "        chef.loc[index, 'has_VIEWED_PHOTOS'] = 1\n",
    "        \n",
    "    # has early deliveries or not\n",
    "    if chef.loc[index, 'EARLY_DELIVERIES'] > 0:\n",
    "        chef.loc[index, 'has_EARLY_DELIVERIES'] = 1\n",
    "\n",
    "    #has late deliveries or not\n",
    "    if chef.loc[index, 'LATE_DELIVERIES'] > 0:\n",
    "        chef.loc[index, 'has_LATE_DELIVERIES'] = 1\n",
    "        \n",
    "    #attended classes or not\n",
    "    if chef.loc[index, 'MASTER_CLASSES_ATTENDED'] > 0:\n",
    "        chef.loc[index, 'has_MASTER_CLASSES_ATTENDED'] = 1   \n",
    "        \n",
    "    # has cancel before noon\n",
    "    if chef.loc[index, 'CANCELLATIONS_BEFORE_NOON'] > 0:\n",
    "        chef.loc[index, 'has_CANCELLATIONS_BEFORE_NOON'] = 1 \n",
    "    # has cancel after noon\n",
    "    if chef.loc[index, 'CANCELLATIONS_AFTER_NOON'] > 0:\n",
    "        chef.loc[index, 'has_CANCELLATIONS_AFTER_NOON'] = 1 \n",
    "        \n",
    "    # has refrigerated locker \n",
    "    if chef.loc[index, 'REFRIGERATED_LOCKER'] > 0:\n",
    "        chef.loc[index, 'has_REFRIGERATED_LOCKER'] = 1\n",
    "    # has package locker\n",
    "    if chef.loc[index, 'PACKAGE_LOCKER'] > 0:\n",
    "        chef.loc[index, 'has_PACKAGE_LOCKER'] = 1\n",
    "        \n",
    "    # Rating level 1, 2, 3, 4, 5\n",
    "    if chef.loc[index, 'MEDIAN_MEAL_RATING'] == 1:\n",
    "        chef.loc[index, 'MEDIAN_MEAL_RATING_1'] = 1\n",
    "        \n",
    "    if chef.loc[index, 'MEDIAN_MEAL_RATING'] == 2:\n",
    "        chef.loc[index, 'MEDIAN_MEAL_RATING_2'] = 1\n",
    "        \n",
    "    if chef.loc[index, 'MEDIAN_MEAL_RATING'] == 3:\n",
    "        chef.loc[index, 'MEDIAN_MEAL_RATING_3'] = 1\n",
    "        \n",
    "    if chef.loc[index, 'MEDIAN_MEAL_RATING'] == 4:\n",
    "        chef.loc[index, 'MEDIAN_MEAL_RATING_4'] = 1\n",
    "        \n",
    "    if chef.loc[index, 'MEDIAN_MEAL_RATING'] == 5:\n",
    "        chef.loc[index, 'MEDIAN_MEAL_RATING_5'] = 1\n",
    "        \n",
    "      # gender-  FEMALE, MALE, UNKNOWN  \n",
    "    if chef.loc[index, 'FAMILY_NAME'] == 'NaN' or chef.loc[index, 'FAMILY_NAME'] == chef.loc[index, 'FIRST_NAME']: \n",
    "        chef.loc[index, 'm_FAMILY_NAME'] = 1\n",
    "        \n",
    "    if chef.loc[index, 'gender'] == 'female' or chef.loc[index, 'gender'] == 'mostly_female':\n",
    "        chef.loc[index, 'FEMALE'] =1\n",
    "        \n",
    "    if chef.loc[index, 'gender'] == 'male' or chef.loc[index, 'gender'] == 'mostly_male':\n",
    "        chef.loc[index, 'MALE'] =1\n",
    "        \n",
    "    if chef.loc[index, 'gender'] == 'unknown' or chef.loc[index, 'gender'] == 'andy':\n",
    "        chef.loc[index, 'UNKNOWN_GENDER'] =1\n",
    "    \n",
    "   \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#dropping columns\n",
    "\n",
    "\n",
    "# can't run more than one time\n",
    "chef = chef.drop('NAME', axis = 1)\n",
    "chef = chef.drop('EMAIL', axis = 1)\n",
    "chef = chef.drop('FIRST_NAME', axis = 1)\n",
    "chef = chef.drop('FAMILY_NAME', axis = 1)\n",
    "chef = chef.drop('gender', axis = 1)\n",
    "\n",
    "chef = chef.drop('EMAIL_domain', axis = 1)\n",
    "chef = chef.drop('DOMAIN_group', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# saving engineered dataset in Excel\n",
    "chef.to_excel('./chef_ready_class.xlsx',\n",
    "                 index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"mark\">Part II- Classification Modeling</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>CROSS_SELL_SUCCESS</th>\n",
       "      <th>TOTAL_MEALS_ORDERED</th>\n",
       "      <th>UNIQUE_MEALS_PURCH</th>\n",
       "      <th>CONTACTS_W_CUSTOMER_SERVICE</th>\n",
       "      <th>PRODUCT_CATEGORIES_VIEWED</th>\n",
       "      <th>AVG_TIME_PER_SITE_VISIT</th>\n",
       "      <th>MOBILE_NUMBER</th>\n",
       "      <th>CANCELLATIONS_BEFORE_NOON</th>\n",
       "      <th>CANCELLATIONS_AFTER_NOON</th>\n",
       "      <th>TASTES_AND_PREFERENCES</th>\n",
       "      <th>PC_LOGINS</th>\n",
       "      <th>MOBILE_LOGINS</th>\n",
       "      <th>WEEKLY_PLAN</th>\n",
       "      <th>EARLY_DELIVERIES</th>\n",
       "      <th>LATE_DELIVERIES</th>\n",
       "      <th>PACKAGE_LOCKER</th>\n",
       "      <th>REFRIGERATED_LOCKER</th>\n",
       "      <th>AVG_PREP_VID_TIME</th>\n",
       "      <th>LARGEST_ORDER_SIZE</th>\n",
       "      <th>MASTER_CLASSES_ATTENDED</th>\n",
       "      <th>MEDIAN_MEAL_RATING</th>\n",
       "      <th>AVG_CLICKS_PER_VISIT</th>\n",
       "      <th>TOTAL_PHOTOS_VIEWED</th>\n",
       "      <th>business_email</th>\n",
       "      <th>junk_email</th>\n",
       "      <th>personal_email</th>\n",
       "      <th>ordinary_meals_ordered</th>\n",
       "      <th>total_logins</th>\n",
       "      <th>total_time_visiting</th>\n",
       "      <th>total_clicks</th>\n",
       "      <th>avg_revenue_per_meal</th>\n",
       "      <th>like_alcohol</th>\n",
       "      <th>total_order_times</th>\n",
       "      <th>log_REVENUE</th>\n",
       "      <th>log_AVG_TIME_PER_SITE_VISIT</th>\n",
       "      <th>log_AVG_PREP_VID_TIME</th>\n",
       "      <th>log_TOTAL_MEALS_ORDERED</th>\n",
       "      <th>log_UNIQUE_MEALS_PURCH</th>\n",
       "      <th>log_CONTACTS_W_CUSTOMER_SERVICE</th>\n",
       "      <th>log_PRODUCT_CATEGORIES_VIEWED</th>\n",
       "      <th>log_AVG_CLICKS_PER_VISIT</th>\n",
       "      <th>log_total_order_times</th>\n",
       "      <th>has_WEEKLY_PLAN</th>\n",
       "      <th>has_VIEWED_PHOTOS</th>\n",
       "      <th>has_EARLY_DELIVERIES</th>\n",
       "      <th>has_LATE_DELIVERIES</th>\n",
       "      <th>has_MASTER_CLASSES_ATTENDED</th>\n",
       "      <th>has_CANCELLATIONS_BEFORE_NOON</th>\n",
       "      <th>has_CANCELLATIONS_AFTER_NOON</th>\n",
       "      <th>has_REFRIGERATED_LOCKER</th>\n",
       "      <th>has_PACKAGE_LOCKER</th>\n",
       "      <th>MEDIAN_MEAL_RATING_1</th>\n",
       "      <th>MEDIAN_MEAL_RATING_2</th>\n",
       "      <th>MEDIAN_MEAL_RATING_3</th>\n",
       "      <th>MEDIAN_MEAL_RATING_4</th>\n",
       "      <th>MEDIAN_MEAL_RATING_5</th>\n",
       "      <th>m_FAMILY_NAME</th>\n",
       "      <th>FEMALE</th>\n",
       "      <th>MALE</th>\n",
       "      <th>UNKNOWN_GENDER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>393.00</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>48.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>336.00</td>\n",
       "      <td>119</td>\n",
       "      <td>28.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.594393</td>\n",
       "      <td>1.681241</td>\n",
       "      <td>1.523746</td>\n",
       "      <td>1.146128</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.230449</td>\n",
       "      <td>1.146128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1365.00</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>40.35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>6</td>\n",
       "      <td>242.10</td>\n",
       "      <td>78</td>\n",
       "      <td>15.689655</td>\n",
       "      <td>0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3.135133</td>\n",
       "      <td>1.605844</td>\n",
       "      <td>1.928396</td>\n",
       "      <td>1.939519</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>0.903090</td>\n",
       "      <td>0.903090</td>\n",
       "      <td>1.113943</td>\n",
       "      <td>1.939519</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800.00</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>19.77</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>138.39</td>\n",
       "      <td>112</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.903090</td>\n",
       "      <td>1.296007</td>\n",
       "      <td>1.799341</td>\n",
       "      <td>1.176091</td>\n",
       "      <td>0.845098</td>\n",
       "      <td>1.041393</td>\n",
       "      <td>0.698970</td>\n",
       "      <td>1.204120</td>\n",
       "      <td>1.176091</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600.00</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>90.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>630.00</td>\n",
       "      <td>98</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.778151</td>\n",
       "      <td>1.954243</td>\n",
       "      <td>1.641474</td>\n",
       "      <td>1.113943</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>1.041393</td>\n",
       "      <td>0.698970</td>\n",
       "      <td>1.146128</td>\n",
       "      <td>1.113943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1490.00</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>40.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>242.28</td>\n",
       "      <td>72</td>\n",
       "      <td>31.702128</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.173186</td>\n",
       "      <td>1.606166</td>\n",
       "      <td>1.928396</td>\n",
       "      <td>1.672098</td>\n",
       "      <td>0.903090</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>1.672098</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1550.00</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>190.18</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>950.90</td>\n",
       "      <td>60</td>\n",
       "      <td>43.055556</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.190332</td>\n",
       "      <td>2.279165</td>\n",
       "      <td>1.896526</td>\n",
       "      <td>1.556303</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.954243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>1.556303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1430.00</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>154.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>7</td>\n",
       "      <td>1079.40</td>\n",
       "      <td>84</td>\n",
       "      <td>23.442623</td>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.155336</td>\n",
       "      <td>2.188084</td>\n",
       "      <td>1.928396</td>\n",
       "      <td>1.785330</td>\n",
       "      <td>0.845098</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>1.785330</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1321.25</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>228.73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1601.11</td>\n",
       "      <td>105</td>\n",
       "      <td>101.634615</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.120985</td>\n",
       "      <td>2.359323</td>\n",
       "      <td>1.799341</td>\n",
       "      <td>1.113943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>1.176091</td>\n",
       "      <td>1.113943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1505.00</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>14.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>99.82</td>\n",
       "      <td>126</td>\n",
       "      <td>94.062500</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.177536</td>\n",
       "      <td>1.154120</td>\n",
       "      <td>1.799341</td>\n",
       "      <td>1.204120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>0.698970</td>\n",
       "      <td>1.255273</td>\n",
       "      <td>1.204120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1493.00</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>49.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>84.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>7</td>\n",
       "      <td>344.82</td>\n",
       "      <td>98</td>\n",
       "      <td>15.715789</td>\n",
       "      <td>0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3.174060</td>\n",
       "      <td>1.692494</td>\n",
       "      <td>1.928396</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>0.903090</td>\n",
       "      <td>1.146128</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REVENUE  CROSS_SELL_SUCCESS  TOTAL_MEALS_ORDERED  UNIQUE_MEALS_PURCH  CONTACTS_W_CUSTOMER_SERVICE  PRODUCT_CATEGORIES_VIEWED  AVG_TIME_PER_SITE_VISIT  MOBILE_NUMBER  CANCELLATIONS_BEFORE_NOON  CANCELLATIONS_AFTER_NOON  TASTES_AND_PREFERENCES  PC_LOGINS  MOBILE_LOGINS  WEEKLY_PLAN  EARLY_DELIVERIES  LATE_DELIVERIES  PACKAGE_LOCKER  REFRIGERATED_LOCKER  AVG_PREP_VID_TIME  LARGEST_ORDER_SIZE  MASTER_CLASSES_ATTENDED  MEDIAN_MEAL_RATING  AVG_CLICKS_PER_VISIT  TOTAL_PHOTOS_VIEWED  business_email  junk_email  personal_email  ordinary_meals_ordered  total_logins  total_time_visiting  total_clicks  avg_revenue_per_meal  like_alcohol  total_order_times  log_REVENUE  log_AVG_TIME_PER_SITE_VISIT  log_AVG_PREP_VID_TIME  log_TOTAL_MEALS_ORDERED  log_UNIQUE_MEALS_PURCH  log_CONTACTS_W_CUSTOMER_SERVICE  log_PRODUCT_CATEGORIES_VIEWED  log_AVG_CLICKS_PER_VISIT  log_total_order_times  has_WEEKLY_PLAN  has_VIEWED_PHOTOS  has_EARLY_DELIVERIES  has_LATE_DELIVERIES  has_MASTER_CLASSES_ATTENDED  \\\n",
       "0   393.00                   1                   14                   6                           12                         10                    48.00              1                          3                         1                       1          5              2            0                 0                2               0                    0               33.4                   1                        0                   1                    17                    0               1           0               0                       8             7               336.00           119             28.071429             0               14.0     2.594393                     1.681241               1.523746                 1.146128                0.778151                         1.079181                       1.000000                  1.230449               1.146128                0                  0                     0                    1                            0   \n",
       "1  1365.00                   1                   87                   3                            8                          8                    40.35              1                          0                         0                       1          5              1           12                 0                2               0                    0               84.8                   1                        0                   3                    13                  170               1           0               0                      84             6               242.10            78             15.689655             0               87.0     3.135133                     1.605844               1.928396                 1.939519                0.477121                         0.903090                       0.903090                  1.113943               1.939519                1                  1                     0                    1                            0   \n",
       "2   800.00                   1                   15                   7                           11                          5                    19.77              1                          3                         0                       1          6              1            1                 0                1               0                    0               63.0                   1                        0                   2                    16                    0               1           0               0                       8             7               138.39           112             53.333333             1               15.0     2.903090                     1.296007               1.799341                 1.176091                0.845098                         1.041393                       0.698970                  1.204120               1.176091                1                  0                     0                    1                            0   \n",
       "3   600.00                   1                   13                   6                           11                          5                    90.00              1                          2                         0                       1          6              1           14                 0                3               0                    0               43.8                   1                        0                   2                    14                    0               1           0               0                       7             7               630.00            98             46.153846             1               13.0     2.778151                     1.954243               1.641474                 1.113943                0.778151                         1.041393                       0.698970                  1.146128               1.113943                1                  0                     0                    1                            0   \n",
       "4  1490.00                   1                   47                   8                            6                         10                    40.38              1                          0                         0                       0          5              1            5                 0                8               0                    0               84.8                   1                        1                   3                    12                  205               1           0               0                      39             6               242.28            72             31.702128             0               47.0     3.173186                     1.606166               1.928396                 1.672098                0.903090                         0.778151                       1.000000                  1.079181               1.672098                1                  1                     0                    1                            1   \n",
       "5  1550.00                   1                   36                   2                            9                          1                   190.18              1                          4                         0                       1          4              1            0                 0                3               1                    0               78.8                   1                        1                   3                    12                    0               0           0               1                      34             5               950.90            60             43.055556             1               36.0     3.190332                     2.279165               1.896526                 1.556303                0.301030                         0.954243                       0.000000                  1.079181               1.556303                0                  0                     0                    1                            1   \n",
       "6  1430.00                   1                   61                   7                            6                          2                   154.20              1                          1                         0                       1          6              1           45                 1                2               1                    1               84.8                   1                        0                   3                    12                  169               1           0               0                      54             7              1079.40            84             23.442623             0               61.0     3.155336                     2.188084               1.928396                 1.785330                0.845098                         0.778151                       0.301030                  1.079181               1.785330                1                  1                     1                    1                            0   \n",
       "7  1321.25                   1                   13                   1                           12                          3                   228.73              1                          0                         0                       1          6              1           13                 0                0               0                    0               63.0                   1                        0                   1                    15                    0               1           0               0                      12             7              1601.11           105            101.634615             1               13.0     3.120985                     2.359323               1.799341                 1.113943                0.000000                         1.079181                       0.477121                  1.176091               1.113943                1                  0                     0                    0                            0   \n",
       "8  1505.00                   1                   16                   1                           12                          5                    14.26              1                          0                         0                       1          6              1           52                 0                1               0                    0               63.0                   1                        0                   2                    18                    0               1           0               0                      15             7                99.82           126             94.062500             1               16.0     3.177536                     1.154120               1.799341                 1.204120                0.000000                         1.079181                       0.698970                  1.255273               1.204120                1                  0                     0                    1                            0   \n",
       "9  1493.00                   0                   95                   3                            6                          8                    49.26              1                          0                         0                       0          6              1           12                 0                2               1                    0               84.8                   1                        1                   3                    14                  147               1           0               0                      92             7               344.82            98             15.715789             0               95.0     3.174060                     1.692494               1.928396                 1.977724                0.477121                         0.778151                       0.903090                  1.146128               1.977724                1                  1                     0                    1                            1   \n",
       "\n",
       "   has_CANCELLATIONS_BEFORE_NOON  has_CANCELLATIONS_AFTER_NOON  has_REFRIGERATED_LOCKER  has_PACKAGE_LOCKER  MEDIAN_MEAL_RATING_1  MEDIAN_MEAL_RATING_2  MEDIAN_MEAL_RATING_3  MEDIAN_MEAL_RATING_4  MEDIAN_MEAL_RATING_5  m_FAMILY_NAME  FEMALE  MALE  UNKNOWN_GENDER  \n",
       "0                              1                             1                        0                   0                     1                     0                     0                     0                     0              1       0     0               1  \n",
       "1                              0                             0                        0                   0                     0                     0                     1                     0                     0              0       0     0               1  \n",
       "2                              1                             0                        0                   0                     0                     1                     0                     0                     0              0       0     0               1  \n",
       "3                              1                             0                        0                   0                     0                     1                     0                     0                     0              0       0     0               1  \n",
       "4                              0                             0                        0                   0                     0                     0                     1                     0                     0              0       0     0               1  \n",
       "5                              1                             0                        0                   1                     0                     0                     1                     0                     0              0       1     0               0  \n",
       "6                              1                             0                        1                   1                     0                     0                     1                     0                     0              0       0     0               1  \n",
       "7                              0                             0                        0                   0                     1                     0                     0                     0                     0              0       0     0               1  \n",
       "8                              0                             0                        0                   0                     0                     1                     0                     0                     0              1       0     0               1  \n",
       "9                              0                             0                        0                   1                     0                     0                     1                     0                     0              0       0     0               1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# importing libraries\n",
    "import random            as rand                     # random number gen\n",
    "import pandas            as pd                       # data science essentials\n",
    "import matplotlib.pyplot as plt                      # data visualization\n",
    "import seaborn           as sns                      # enhanced data viz\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "import statsmodels.formula.api as smf                # logistic regression\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor    # KNN for regression\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "\n",
    "\n",
    "# libraries for classification trees\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import export_graphviz             # exports graphics\n",
    "from six import StringIO                             # saves objects in memory\n",
    "from IPython.display import Image                    # displays on frontend\n",
    "import pydotplus                                     # interprets dot objects\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV     # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer                    # customizable scorer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm\n",
    "\n",
    "# loading data\n",
    "chef_class = pd.read_excel('./chef_ready_class.xlsx')\n",
    "\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "\n",
    "# displaying the head of the dataset\n",
    "chef_class.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#UDF FUNCTION\n",
    "########################################\n",
    "# optimal_neighbors\n",
    "########################################\n",
    "def optimal_neighbors(X_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.25,\n",
    "                      seed=219,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "X_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "standardize   : whether or not to standardize the X data, default True\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 219\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "show_viz      : display or surpress k-neigbors visualization, default True\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing X_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(X_data)\n",
    "        X_scaled           = scaler.transform(X_data)\n",
    "        X_scaled_df        = pd.DataFrame(X_scaled)\n",
    "        X_data             = X_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(X_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(X_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization\n",
    "    if show_viz == True:\n",
    "        # plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1\n",
    "\n",
    "\n",
    "########################################\n",
    "# visual_cm\n",
    "########################################\n",
    "def visual_cm(true_y, pred_y, labels = None):\n",
    "    \"\"\"\n",
    "Creates a visualization of a confusion matrix.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "true_y : true values for the response variable\n",
    "pred_y : predicted values for the response variable\n",
    "labels : , default None\n",
    "    \"\"\"\n",
    "    # visualizing the confusion matrix\n",
    "\n",
    "    # setting labels\n",
    "    lbls = labels\n",
    "    \n",
    "\n",
    "    # declaring a confusion matrix object\n",
    "    cm = confusion_matrix(y_true = true_y,\n",
    "                          y_pred = pred_y)\n",
    "\n",
    "\n",
    "    # heatmap\n",
    "    sns.heatmap(cm,\n",
    "                annot       = True,\n",
    "                xticklabels = lbls,\n",
    "                yticklabels = lbls,\n",
    "                cmap        = 'Blues',\n",
    "                fmt         = 'g')\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#UDF FUNCTION\n",
    "########################################\n",
    "# display_tree\n",
    "########################################\n",
    "def display_tree(tree, feature_df, height = 500, width = 800):\n",
    "    \"\"\"\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    tree       : fitted tree model object\n",
    "        fitted CART model to visualized\n",
    "    feature_df : DataFrame\n",
    "        DataFrame of explanatory features (used to generate labels)\n",
    "    height     : int, default 500\n",
    "        height in pixels to which to constrain image in html\n",
    "    width      : int, default 800\n",
    "        width in pixels to which to constrain image in html\n",
    "    \"\"\"\n",
    "\n",
    "    # visualizing the tree\n",
    "    dot_data = StringIO()\n",
    "\n",
    "    \n",
    "    # exporting tree to graphviz\n",
    "    export_graphviz(decision_tree      = tree,\n",
    "                    out_file           = dot_data,\n",
    "                    filled             = True,\n",
    "                    rounded            = True,\n",
    "                    special_characters = True,\n",
    "                    feature_names      = feature_df.columns)\n",
    "\n",
    "\n",
    "    # declaring a graph object\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "\n",
    "    # creating image\n",
    "    img = Image(graph.create_png(),\n",
    "                height = height,\n",
    "                width  = width)\n",
    "    \n",
    "    return img\n",
    "\n",
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = x_train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(pd.np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#UDF FUNCTION\n",
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(pd.np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('./Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# declaring explanatory variables\n",
    "chef_class_data = chef_class.drop('CROSS_SELL_SUCCESS', axis = 1)\n",
    "\n",
    "\n",
    "# declaring response variable\n",
    "chef_class_target = chef_class.loc[ : , 'CROSS_SELL_SUCCESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            chef_class_data,\n",
    "            chef_class_target,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219,\n",
    "            stratify     = chef_class_target)\n",
    "\n",
    "\n",
    "# merging training data for statsmodels\n",
    "chef_class_train = pd.concat([x_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Response Variable Proportions (Training Set)\n",
      "--------------------------------------------\n",
      "1    0.68\n",
      "0    0.32\n",
      "Name: CROSS_SELL_SUCCESS, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "Response Variable Proportions (Testing Set)\n",
      "--------------------------------------------\n",
      "1    0.68\n",
      "0    0.32\n",
      "Name: CROSS_SELL_SUCCESS, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "\n",
    "Response Variable Proportions (Training Set)\n",
    "--------------------------------------------\n",
    "{y_train.value_counts(normalize = True).round(decimals = 2)}\n",
    "\n",
    "\n",
    "\n",
    "Response Variable Proportions (Testing Set)\n",
    "--------------------------------------------\n",
    "{y_test.value_counts(normalize = True).round(decimals = 2)}\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#for val in chef_class_data:\n",
    "#    print(f\" {val} + \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.516824\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>CROSS_SELL_SUCCESS</td> <th>  No. Observations:  </th>  <td>  1459</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>Logit</td>       <th>  Df Residuals:      </th>  <td>  1444</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>        <th>  Df Model:          </th>  <td>    14</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 05 Jul 2021</td>  <th>  Pseudo R-squ.:     </th>  <td>0.1770</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:15:03</td>      <th>  Log-Likelihood:    </th> <td> -754.05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>        <th>  LL-Null:           </th> <td> -916.19</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>  LLR p-value:       </th> <td>9.978e-61</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                   <td>   -0.1916</td> <td>    0.306</td> <td>   -0.626</td> <td> 0.531</td> <td>   -0.791</td> <td>    0.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MOBILE_NUMBER</th>               <td>    0.9597</td> <td>    0.182</td> <td>    5.272</td> <td> 0.000</td> <td>    0.603</td> <td>    1.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CANCELLATIONS_BEFORE_NOON</th>   <td>    0.2916</td> <td>    0.048</td> <td>    6.070</td> <td> 0.000</td> <td>    0.197</td> <td>    0.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CANCELLATIONS_AFTER_NOON</th>    <td>   -0.2925</td> <td>    0.146</td> <td>   -2.001</td> <td> 0.045</td> <td>   -0.579</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TASTES_AND_PREFERENCES</th>      <td>    0.3303</td> <td>    0.139</td> <td>    2.369</td> <td> 0.018</td> <td>    0.057</td> <td>    0.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REFRIGERATED_LOCKER</th>         <td>    0.5724</td> <td>    0.217</td> <td>    2.642</td> <td> 0.008</td> <td>    0.148</td> <td>    0.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_FAMILY_NAME</th>               <td>   -1.2091</td> <td>    0.137</td> <td>   -8.843</td> <td> 0.000</td> <td>   -1.477</td> <td>   -0.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FEMALE</th>                      <td>   -0.7154</td> <td>    0.229</td> <td>   -3.123</td> <td> 0.002</td> <td>   -1.164</td> <td>   -0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MALE</th>                        <td>    0.3462</td> <td>    0.169</td> <td>    2.054</td> <td> 0.040</td> <td>    0.016</td> <td>    0.677</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>personal_email</th>              <td>   -0.6067</td> <td>    0.149</td> <td>   -4.078</td> <td> 0.000</td> <td>   -0.898</td> <td>   -0.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>junk_email</th>                  <td>   -1.9986</td> <td>    0.178</td> <td>  -11.242</td> <td> 0.000</td> <td>   -2.347</td> <td>   -1.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CONTACTS_W_CUSTOMER_SERVICE</th> <td>    0.0754</td> <td>    0.030</td> <td>    2.534</td> <td> 0.011</td> <td>    0.017</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EARLY_DELIVERIES</th>            <td>    0.0530</td> <td>    0.028</td> <td>    1.866</td> <td> 0.062</td> <td>   -0.003</td> <td>    0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>like_alcohol</th>                <td>   -0.2948</td> <td>    0.141</td> <td>   -2.094</td> <td> 0.036</td> <td>   -0.571</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_MASTER_CLASSES_ATTENDED</th> <td>    0.2713</td> <td>    0.127</td> <td>    2.129</td> <td> 0.033</td> <td>    0.022</td> <td>    0.521</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:     CROSS_SELL_SUCCESS   No. Observations:                 1459\n",
       "Model:                          Logit   Df Residuals:                     1444\n",
       "Method:                           MLE   Df Model:                           14\n",
       "Date:                Mon, 05 Jul 2021   Pseudo R-squ.:                  0.1770\n",
       "Time:                        10:15:03   Log-Likelihood:                -754.05\n",
       "converged:                       True   LL-Null:                       -916.19\n",
       "Covariance Type:            nonrobust   LLR p-value:                 9.978e-61\n",
       "===============================================================================================\n",
       "                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "Intercept                      -0.1916      0.306     -0.626      0.531      -0.791       0.408\n",
       "MOBILE_NUMBER                   0.9597      0.182      5.272      0.000       0.603       1.316\n",
       "CANCELLATIONS_BEFORE_NOON       0.2916      0.048      6.070      0.000       0.197       0.386\n",
       "CANCELLATIONS_AFTER_NOON       -0.2925      0.146     -2.001      0.045      -0.579      -0.006\n",
       "TASTES_AND_PREFERENCES          0.3303      0.139      2.369      0.018       0.057       0.603\n",
       "REFRIGERATED_LOCKER             0.5724      0.217      2.642      0.008       0.148       0.997\n",
       "m_FAMILY_NAME                  -1.2091      0.137     -8.843      0.000      -1.477      -0.941\n",
       "FEMALE                         -0.7154      0.229     -3.123      0.002      -1.164      -0.266\n",
       "MALE                            0.3462      0.169      2.054      0.040       0.016       0.677\n",
       "personal_email                 -0.6067      0.149     -4.078      0.000      -0.898      -0.315\n",
       "junk_email                     -1.9986      0.178    -11.242      0.000      -2.347      -1.650\n",
       "CONTACTS_W_CUSTOMER_SERVICE     0.0754      0.030      2.534      0.011       0.017       0.134\n",
       "EARLY_DELIVERIES                0.0530      0.028      1.866      0.062      -0.003       0.109\n",
       "like_alcohol                   -0.2948      0.141     -2.094      0.036      -0.571      -0.019\n",
       "has_MASTER_CLASSES_ATTENDED     0.2713      0.127      2.129      0.033       0.022       0.521\n",
       "===============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a logistic regression model object. \n",
    "# Prepare x-variables sets\n",
    "logistic_small = smf.logit(formula = \"\"\"CROSS_SELL_SUCCESS ~ \n",
    " MOBILE_NUMBER + \n",
    " CANCELLATIONS_BEFORE_NOON + \n",
    " CANCELLATIONS_AFTER_NOON + \n",
    " TASTES_AND_PREFERENCES + \n",
    " REFRIGERATED_LOCKER + \n",
    " m_FAMILY_NAME + \n",
    " FEMALE + \n",
    " MALE + \n",
    " personal_email + \n",
    " junk_email+\n",
    " CONTACTS_W_CUSTOMER_SERVICE+\n",
    " EARLY_DELIVERIES+\n",
    " like_alcohol+\n",
    " has_MASTER_CLASSES_ATTENDED\n",
    "\n",
    " \"\"\",\n",
    "    data    = chef_class_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_logistic = logistic_small.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# creating a dictionary to store candidate models\n",
    "\n",
    "candidate_dict = {\n",
    "  # significant variables only(set1)\n",
    " 'logit_sig1'    : [ 'MOBILE_NUMBER' , 'CANCELLATIONS_BEFORE_NOON', 'TASTES_AND_PREFERENCES',\n",
    "                    'REFRIGERATED_LOCKER', 'm_FAMILY_NAME', 'FEMALE','MALE','personal_email','junk_email',\n",
    "                    'CONTACTS_W_CUSTOMER_SERVICE','EARLY_DELIVERIES','MEDIAN_MEAL_RATING'],\n",
    "    \n",
    " # significant variables only (set 2)- insignt from tree feature importance\n",
    " 'logit_sig2'    : [ 'MOBILE_NUMBER' , 'CANCELLATIONS_BEFORE_NOON', 'CANCELLATIONS_AFTER_NOON', 'TASTES_AND_PREFERENCES',\n",
    "                    'REFRIGERATED_LOCKER', 'm_FAMILY_NAME', 'FEMALE','MALE','personal_email','junk_email',\n",
    "                    'CONTACTS_W_CUSTOMER_SERVICE','EARLY_DELIVERIES','like_alcohol','has_MASTER_CLASSES_ATTENDED'],\n",
    "\n",
    " # significant variables only(set 3) \n",
    "\n",
    " 'logit_sig3'    : [ 'MOBILE_NUMBER' , 'CANCELLATIONS_BEFORE_NOON', 'CANCELLATIONS_AFTER_NOON', 'TASTES_AND_PREFERENCES',\n",
    "                   'REFRIGERATED_LOCKER', 'm_FAMILY_NAME', 'FEMALE','MALE','personal_email','junk_email',\n",
    "                    'CONTACTS_W_CUSTOMER_SERVICE','like_alcohol','has_MASTER_CLASSES_ATTENDED'],\n",
    " # significant variables only(set 4) \n",
    "\n",
    " 'logit_sig4'    :[ 'has_MASTER_CLASSES_ATTENDED','has_CANCELLATIONS_BEFORE_NOON', 'junk_email','personal_email',\n",
    " \n",
    "                   'MOBILE_NUMBER', 'TASTES_AND_PREFERENCES', 'REFRIGERATED_LOCKER','m_FAMILY_NAME','FEMALE'],\n",
    "    \n",
    " # significant variables only(set 5) \n",
    " 'logit_sig5'    :['MOBILE_NUMBER', 'CANCELLATIONS_BEFORE_NOON', 'TASTES_AND_PREFERENCES', 'REFRIGERATED_LOCKER',\n",
    " 'm_FAMILY_NAME', 'FEMALE','MALE','personal_email','junk_email','CONTACTS_W_CUSTOMER_SERVICE','like_alcohol'],\n",
    "    \n",
    " # significant variables only(set 6) \n",
    " 'logit_sig6'    :['MOBILE_NUMBER', 'CANCELLATIONS_BEFORE_NOON', 'TASTES_AND_PREFERENCES', 'REFRIGERATED_LOCKER',\n",
    " 'm_FAMILY_NAME', 'FEMALE','MALE','personal_email','business_email','CONTACTS_W_CUSTOMER_SERVICE','like_alcohol']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/--------------------------\\\n",
      "|Explanatory Variable Sets |\n",
      "\\--------------------------/\n",
      "\n",
      "\n",
      "First Significant p-value Model:\n",
      "--------------------------------\n",
      "['MOBILE_NUMBER', 'CANCELLATIONS_BEFORE_NOON', 'TASTES_AND_PREFERENCES', 'REFRIGERATED_LOCKER', 'm_FAMILY_NAME', 'FEMALE', 'MALE', 'personal_email', 'junk_email', 'CONTACTS_W_CUSTOMER_SERVICE', 'EARLY_DELIVERIES', 'MEDIAN_MEAL_RATING']\n",
      "\n",
      "\n",
      "Second Significant p-value Model:\n",
      "--------------------------------\n",
      "['MOBILE_NUMBER', 'CANCELLATIONS_BEFORE_NOON', 'CANCELLATIONS_AFTER_NOON', 'TASTES_AND_PREFERENCES', 'REFRIGERATED_LOCKER', 'm_FAMILY_NAME', 'FEMALE', 'MALE', 'personal_email', 'junk_email', 'CONTACTS_W_CUSTOMER_SERVICE', 'EARLY_DELIVERIES', 'like_alcohol', 'has_MASTER_CLASSES_ATTENDED']\n",
      "\n",
      "Third Significant p-value Model:\n",
      "--------------------------------\n",
      "['MOBILE_NUMBER', 'CANCELLATIONS_BEFORE_NOON', 'CANCELLATIONS_AFTER_NOON', 'TASTES_AND_PREFERENCES', 'REFRIGERATED_LOCKER', 'm_FAMILY_NAME', 'FEMALE', 'MALE', 'personal_email', 'junk_email', 'CONTACTS_W_CUSTOMER_SERVICE', 'like_alcohol', 'has_MASTER_CLASSES_ATTENDED']\n",
      "\n",
      "\n",
      "Fourth Significant p-value Model:\n",
      "--------------------------------\n",
      "['has_MASTER_CLASSES_ATTENDED', 'has_CANCELLATIONS_BEFORE_NOON', 'junk_email', 'personal_email', 'MOBILE_NUMBER', 'TASTES_AND_PREFERENCES', 'REFRIGERATED_LOCKER', 'm_FAMILY_NAME', 'FEMALE']\n",
      "\n",
      "Fifth Significant p-value Model:\n",
      "--------------------------------\n",
      "['MOBILE_NUMBER', 'CANCELLATIONS_BEFORE_NOON', 'TASTES_AND_PREFERENCES', 'REFRIGERATED_LOCKER', 'm_FAMILY_NAME', 'FEMALE', 'MALE', 'personal_email', 'junk_email', 'CONTACTS_W_CUSTOMER_SERVICE', 'like_alcohol']\n",
      "\n",
      "\n",
      "Sixth Significant p-value Model:\n",
      "--------------------------------\n",
      "['MOBILE_NUMBER', 'CANCELLATIONS_BEFORE_NOON', 'TASTES_AND_PREFERENCES', 'REFRIGERATED_LOCKER', 'm_FAMILY_NAME', 'FEMALE', 'MALE', 'personal_email', 'business_email', 'CONTACTS_W_CUSTOMER_SERVICE', 'like_alcohol']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing candidate variable sets\n",
    "print(f\"\"\"\n",
    "/--------------------------\\\\\n",
    "|Explanatory Variable Sets |\n",
    "\\\\--------------------------/\n",
    "\n",
    "\n",
    "First Significant p-value Model:\n",
    "--------------------------------\n",
    "{candidate_dict['logit_sig1']}\n",
    "\n",
    "\n",
    "Second Significant p-value Model:\n",
    "--------------------------------\n",
    "{candidate_dict['logit_sig2']}\n",
    "\n",
    "Third Significant p-value Model:\n",
    "--------------------------------\n",
    "{candidate_dict['logit_sig3']}\n",
    "\n",
    "\n",
    "Fourth Significant p-value Model:\n",
    "--------------------------------\n",
    "{candidate_dict['logit_sig4']}\n",
    "\n",
    "Fifth Significant p-value Model:\n",
    "--------------------------------\n",
    "{candidate_dict['logit_sig5']}\n",
    "\n",
    "\n",
    "Sixth Significant p-value Model:\n",
    "--------------------------------\n",
    "{candidate_dict['logit_sig6']}\n",
    "\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This book will only show models for 'logit_sig6'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Training ACCURACY: 0.7608\n",
      "LogReg Testing  ACCURACY: 0.7577\n",
      "LogReg Train-Test Gap   : 0.0031\n"
     ]
    }
   ],
   "source": [
    "# train/test split with the 'logit_sig6'\n",
    "chef_class_data   =  chef_class.loc[ : , candidate_dict['logit_sig6']]\n",
    "chef_class_target =  chef_class.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "\n",
    "# this is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            chef_class_data,\n",
    "            chef_class_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.25,\n",
    "            stratify     = chef_class_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('LogReg Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('LogReg Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('LogReg Train-Test Gap   :', abs(logreg_train_score - logreg_test_score).round(4))\n",
    "logreg_test_gap = abs(logreg_train_score - logreg_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 72  84]\n",
      " [ 34 297]]\n"
     ]
    }
   ],
   "source": [
    "# creating a confusion matrix\n",
    "print(confusion_matrix(y_true = y_test,\n",
    "                       y_pred = logreg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 72\n",
      "False Positives: 84\n",
      "False Negatives: 34\n",
      "True Positives : 297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6794\n"
     ]
    }
   ],
   "source": [
    "# area under the roc curve (auc)\n",
    "print(roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('intercept', -1.9371)\n",
      "('MOBILE_NUMBER', 0.8911)\n",
      "('CANCELLATIONS_BEFORE_NOON', 0.2883)\n",
      "('TASTES_AND_PREFERENCES', 0.3436)\n",
      "('REFRIGERATED_LOCKER', 0.5356)\n",
      "('m_FAMILY_NAME', -1.1685)\n",
      "('FEMALE', -0.6273)\n",
      "('MALE', 0.3556)\n",
      "('personal_email', 1.3149)\n",
      "('business_email', 1.8994)\n",
      "('CONTACTS_W_CUSTOMER_SERVICE', 0.077)\n",
      "('like_alcohol', -0.3071)\n"
     ]
    }
   ],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "logreg_model_values = zip(chef_class[candidate_dict['logit_sig6']].columns,\n",
    "                          logreg_fit.coef_.ravel().round(decimals = 4))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "logreg_model_lst = [('intercept', logreg_fit.intercept_[0].round(decimals = 4))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in logreg_model_values:\n",
    "    logreg_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in logreg_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Tree Training ACCURACY: 0.9232\n",
      "Full Tree Testing ACCURACY : 0.7023\n",
      "Full Tree AUC Score: 0.6657\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "full_tree_fit = full_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "full_tree_pred = full_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Full Tree Training ACCURACY:', full_tree_fit.score(x_train,\n",
    "                                                     y_train).round(4))\n",
    "\n",
    "print('Full Tree Testing ACCURACY :', full_tree_fit.score(x_test,\n",
    "                                                     y_test).round(4))\n",
    "\n",
    "print('Full Tree AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                                            y_score = full_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "full_tree_train_score = full_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "full_tree_test_score  = full_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC\n",
    "full_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = full_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 88\n",
      "False Positives: 68\n",
      "False Negatives: 77\n",
      "True Positives : 254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "full_tree_tn, \\\n",
    "full_tree_fp, \\\n",
    "full_tree_fn, \\\n",
    "full_tree_tp = confusion_matrix(y_true = y_test, y_pred = full_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {full_tree_tn}\n",
    "False Positives: {full_tree_fp}\n",
    "False Negatives: {full_tree_fn}\n",
    "True Positives : {full_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# calling display_tree\n",
    "#display_tree(tree       = full_tree_fit,\n",
    " #            feature_df = x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7526\n",
      "Testing  ACCURACY: 0.7721\n",
      "AUC Score        : 0.7154\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "pruned_tree = DecisionTreeClassifier(max_depth = 4,\n",
    "                                     min_samples_leaf = 25,\n",
    "                                     random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "pruned_tree_fit  = pruned_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "pruned_tree_pred = pruned_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', pruned_tree_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', pruned_tree_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = pruned_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = pruned_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = pruned_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = pruned_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 87\n",
      "False Positives: 69\n",
      "False Negatives: 42\n",
      "True Positives : 289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = pruned_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# calling display_tree\n",
    "#display_tree(tree       = pruned_tree_fit,\n",
    " #            feature_df = x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# plotting feature importance\n",
    "#plot_feature_importances(pruned_tree_fit,\n",
    "#                         train = x_train,\n",
    "#                         export = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model         AUC Score      TN, FP, FN, TP\n",
      "-----         ---------      --------------\n",
      "Logistic      0.6794         (72, 84, 34, 297)\n",
      "Full Tree     0.6657         (88, 68, 77, 254)\n",
      "Pruned Tree   0.7154         (87, 69, 42, 289)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comparing results\n",
    "print(f\"\"\"\n",
    "Model         AUC Score      TN, FP, FN, TP\n",
    "-----         ---------      --------------\n",
    "Logistic      {logreg_auc_score}         {logreg_tn, logreg_fp, logreg_fn, logreg_tp}\n",
    "Full Tree     {full_tree_auc_score}         {full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp}\n",
    "Pruned Tree   {pruned_tree_auc_score}         {pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Name'    : ['Logistic', 'Full Tree', 'Pruned Tree'],\n",
    "           \n",
    "    'AUC Score' : [logreg_auc_score, full_tree_auc_score, pruned_tree_auc_score],\n",
    "    \n",
    "    'Training Accuracy' : [logreg_train_score, full_tree_train_score,\n",
    "                           pruned_tree_train_score],\n",
    "           \n",
    "    'Testing Accuracy'  : [logreg_test_score, full_tree_test_score,\n",
    "                           pruned_tree_test_score],\n",
    "\n",
    "    'Confusion Matrix'  : [(logreg_tn, logreg_fp, logreg_fn, logreg_tp),\n",
    "                           (full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp),\n",
    "                           (pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp)]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)\n",
    "\n",
    "\n",
    "# sending model results to Excel\n",
    "model_performance.to_excel('./classification_model_performance.xlsx',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is: 18\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "# determining the optimal number of neighbors\n",
    "opt_neighbors = optimal_neighbors(X_data        = chef_class_data,\n",
    "                                  y_data        = chef_class_target,\n",
    "                                  response_type = 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7587\n",
      "Testing  ACCURACY: 0.7454\n",
      "AUC Score        : 0.6703\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the data\n",
    "scaler.fit(chef_class_data)\n",
    "\n",
    "\n",
    "# TRANSFORMING the data\n",
    "x_scaled     = scaler.transform(chef_class_data)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "x_scaled_df  = pd.DataFrame(x_scaled) \n",
    "\n",
    "\n",
    "# train-test split with the scaled data\n",
    "x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "            x_scaled_df,\n",
    "            chef_class_target,\n",
    "            random_state = 219,\n",
    "            test_size = 0.25,\n",
    "            stratify = chef_class_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = opt_neighbors)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "knn_fit = knn_opt.fit(x_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "knn_pred = knn_fit.predict(x_test_scaled)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_fit.score(x_train_scaled, y_train_scaled).round(4))\n",
    "print('Testing  ACCURACY:', knn_fit.score(x_test_scaled, y_test_scaled).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data\n",
    "knn_train_score = knn_fit.score(x_train_scaled, y_train_scaled).round(4)\n",
    "knn_test_score  = knn_fit.score(x_test_scaled, y_test_scaled).round(4)\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "knn_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# calling the visual_cm function\n",
    "#visual_cm(true_y = y_test,\n",
    "#          pred_y = knn_pred,\n",
    "#          labels = ['CROSS SUCCESS', 'Not SUCCESS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 87\n",
      "False Positives: 69\n",
      "False Negatives: 42\n",
      "True Positives : 289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "knn_tree_tn, \\\n",
    "knn_tree_fp, \\\n",
    "knn_tree_fn, \\\n",
    "knn_tree_tp = confusion_matrix(y_true = y_test, y_pred = knn_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-2840549dcf9e>:6: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  C_space          = pd.np.arange(0.1, 5.0, 0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameters  : {'warm_start': False, 'solver': 'sag', 'C': 3.3000000000000003}\n",
      "Tuned CV AUC      : 0.6869\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# RandomizedSearchCV\n",
    "########################################\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "C_space          = pd.np.arange(0.1, 5.0, 0.1)\n",
    "warm_start_space = [True, False]\n",
    "solver_space     = ['newton-cg', 'sag', 'lbfgs']\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'C'          : C_space,\n",
    "              'warm_start' : warm_start_space,\n",
    "              'solver'     : solver_space}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "lr_tuned = LogisticRegression(random_state = 219,\n",
    "                              max_iter     = 1000)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "lr_tuned_cv = RandomizedSearchCV(estimator           = lr_tuned,   # the model object\n",
    "                                 param_distributions = param_grid, # parameters to tune\n",
    "                                 cv                  = 3,          # how many folds in cross-validation\n",
    "                                 n_iter              = 250,        # number of combinations of hyperparameters to try\n",
    "                                 random_state        = 219,        # starting point for random sequence\n",
    "                                 scoring = make_scorer(\n",
    "                                           roc_auc_score,\n",
    "                                           needs_threshold = False)) # scoring criteria (AUC)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "lr_tuned_cv.fit(chef_class_data, chef_class_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", lr_tuned_cv.best_params_)\n",
    "print(\"Tuned CV AUC      :\", lr_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Tuned Training ACCURACY: 0.7587\n",
      "LR Tuned Testing  ACCURACY: 0.77\n",
      "LR Tuned AUC Score        : 0.6969\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "lr_tuned = lr_tuned_cv.best_estimator_\n",
    "\n",
    "\n",
    "# FIT step is not needed\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "lr_tuned_pred = lr_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('LR Tuned Training ACCURACY:', lr_tuned.score(x_train, y_train).round(4))\n",
    "print('LR Tuned Testing  ACCURACY:', lr_tuned.score(x_test, y_test).round(4))\n",
    "print('LR Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = lr_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lr_tuned_train_score = lr_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "lr_tuned_test_score  = lr_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "lr_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = lr_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 77\n",
      "False Positives: 79\n",
      "False Negatives: 33\n",
      "True Positives : 298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "lr_tuned_tn, \\\n",
    "lr_tuned_fp, \\\n",
    "lr_tuned_fn, \\\n",
    "lr_tuned_tp = confusion_matrix(y_true = y_test, y_pred = lr_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {lr_tuned_tn}\n",
    "False Positives: {lr_tuned_fp}\n",
    "False Negatives: {lr_tuned_fn}\n",
    "True Positives : {lr_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6794</td>\n",
       "      <td>0.7608</td>\n",
       "      <td>0.7577</td>\n",
       "      <td>(72, 84, 34, 297)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6657</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>(88, 68, 77, 254)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>0.7721</td>\n",
       "      <td>(87, 69, 42, 289)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.6969</td>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>(77, 79, 33, 298)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0     Logistic     0.6794             0.7608            0.7577  (72, 84, 34, 297)\n",
       "1    Full Tree     0.6657             0.9232            0.7023  (88, 68, 77, 254)\n",
       "2  Pruned Tree     0.7154             0.7526            0.7721  (87, 69, 42, 289)\n",
       "3     Tuned LR     0.6969             0.7587            0.7700  (77, 79, 33, 298)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading model performance\n",
    "model_performance = pd.read_excel('./classification_model_performance.xlsx')\n",
    "\n",
    "\n",
    "# declaring model performance objects\n",
    "lr_train_acc = lr_tuned.score(x_train, y_train).round(4)\n",
    "lr_test_acc  = lr_tuned.score(x_test, y_test).round(4)\n",
    "lr_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = lr_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned LR',\n",
    "                           'Training Accuracy' : lr_train_acc,\n",
    "                           'Testing Accuracy'  : lr_test_acc,\n",
    "                           'AUC Score'         : lr_auc,\n",
    "                           'Confusion Matrix'  : (lr_tuned_tn,\n",
    "                                                  lr_tuned_fp,\n",
    "                                                  lr_tuned_fn,\n",
    "                                                  lr_tuned_tp)},\n",
    "                           ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-c24c4eca6c99>:4: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  depth_space     = pd.np.arange(1, 25, 1)\n",
      "<ipython-input-51-c24c4eca6c99>:5: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  leaf_space      = pd.np.arange(1, 100, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameters  : {'splitter': 'random', 'min_samples_leaf': 9, 'max_depth': 8, 'criterion': 'gini'}\n",
      "Tuned Training AUC: 0.6891\n"
     ]
    }
   ],
   "source": [
    "# declaring a hyperparameter space\n",
    "criterion_space = ['gini', 'entropy']\n",
    "splitter_space  = ['best', 'random']\n",
    "depth_space     = pd.np.arange(1, 25, 1)\n",
    "leaf_space      = pd.np.arange(1, 100, 1)\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'criterion'        : criterion_space,\n",
    "              'splitter'         : splitter_space,\n",
    "              'max_depth'        : depth_space,\n",
    "              'min_samples_leaf' : leaf_space}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "tuned_tree = DecisionTreeClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# RandomizedSearchCV object\n",
    "tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "                                   param_distributions   = param_grid,\n",
    "                                   cv                    = 3,\n",
    "                                   n_iter                = 1000,\n",
    "                                   random_state          = 219,\n",
    "                                   scoring = make_scorer(roc_auc_score,\n",
    "                                             needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "tuned_tree_cv.fit(chef_class_data, chef_class_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7656\n",
      "Testing  ACCURACY: 0.809\n",
      "AUC Score        : 0.7545\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "tree_tuned = tuned_tree_cv.best_estimator_\n",
    "\n",
    "\n",
    "# FIT step is not needed\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "tree_tuned_pred = tree_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', tree_tuned.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "tree_tuned_train_score = tree_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "tree_tuned_test_score  = tree_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "tree_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = tree_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 94\n",
      "False Positives: 62\n",
      "False Negatives: 31\n",
      "True Positives : 300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_tree_tn, \\\n",
    "tuned_tree_fp, \\\n",
    "tuned_tree_fn, \\\n",
    "tuned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_tree_tn}\n",
    "False Positives: {tuned_tree_fp}\n",
    "False Negatives: {tuned_tree_fn}\n",
    "True Positives : {tuned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6794</td>\n",
       "      <td>0.7608</td>\n",
       "      <td>0.7577</td>\n",
       "      <td>(72, 84, 34, 297)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6657</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>(88, 68, 77, 254)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>0.7721</td>\n",
       "      <td>(87, 69, 42, 289)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.6969</td>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>(77, 79, 33, 298)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree(FINAL MODEL)</td>\n",
       "      <td>0.7545</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>(94, 62, 31, 300)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0                 Logistic     0.6794             0.7608            0.7577  (72, 84, 34, 297)\n",
       "1                Full Tree     0.6657             0.9232            0.7023  (88, 68, 77, 254)\n",
       "2              Pruned Tree     0.7154             0.7526            0.7721  (87, 69, 42, 289)\n",
       "3                 Tuned LR     0.6969             0.7587            0.7700  (77, 79, 33, 298)\n",
       "4  Tuned Tree(FINAL MODEL)     0.7545             0.7656            0.8090  (94, 62, 31, 300)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "tree_train_acc = tree_tuned.score(x_train, y_train).round(4)\n",
    "tree_test_acc  = tree_tuned.score(x_test, y_test).round(4)\n",
    "tree_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = tree_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned Tree(FINAL MODEL)',\n",
    "                           'Training Accuracy' : tree_train_acc,\n",
    "                           'Testing Accuracy'  : tree_test_acc,\n",
    "                           'AUC Score'         : tree_auc,\n",
    "                           'Confusion Matrix'  : (tuned_tree_tn,\n",
    "                                                  tuned_tree_fp,\n",
    "                                                  tuned_tree_fn,\n",
    "                                                  tuned_tree_tp)},\n",
    "                           ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# displaying the tree\n",
    "#display_tree(tree = tree_tuned,\n",
    " #            feature_df = chef_class_data,\n",
    " #            height = 800,\n",
    " #            width  = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 100,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = None,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.9232\n",
      "Testing  ACCURACY: 0.7495\n",
      "AUC Score        : 0.6886\n"
     ]
    }
   ],
   "source": [
    "# FITTING the training data\n",
    "rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# plotting feature importances\n",
    "#plot_feature_importances(rf_default_fit,\n",
    "#                         train = x_train,\n",
    "#                         export = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 81\n",
      "False Positives: 75\n",
      "False Negatives: 47\n",
      "True Positives : 284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "rf_tn, \\\n",
    "rf_fp, \\\n",
    "rf_fn, \\\n",
    "rf_tp = confusion_matrix(y_true = y_test, y_pred = rf_default_fit_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {rf_tn}\n",
    "False Positives: {rf_fp}\n",
    "False Negatives: {rf_fn}\n",
    "True Positives : {rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6794</td>\n",
       "      <td>0.7608</td>\n",
       "      <td>0.7577</td>\n",
       "      <td>(72, 84, 34, 297)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6657</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>(88, 68, 77, 254)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>0.7721</td>\n",
       "      <td>(87, 69, 42, 289)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.6969</td>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>(77, 79, 33, 298)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree(FINAL MODEL)</td>\n",
       "      <td>0.7545</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>(94, 62, 31, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>(81, 75, 47, 284)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0                 Logistic     0.6794             0.7608            0.7577  (72, 84, 34, 297)\n",
       "1                Full Tree     0.6657             0.9232            0.7023  (88, 68, 77, 254)\n",
       "2              Pruned Tree     0.7154             0.7526            0.7721  (87, 69, 42, 289)\n",
       "3                 Tuned LR     0.6969             0.7587            0.7700  (77, 79, 33, 298)\n",
       "4  Tuned Tree(FINAL MODEL)     0.7545             0.7656            0.8090  (94, 62, 31, 300)\n",
       "5            Random Forest     0.6886             0.9232            0.7495  (81, 75, 47, 284)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "rf_train_acc = rf_default_fit.score(x_train, y_train).round(4)\n",
    "rf_test_acc  = rf_default_fit.score(x_test, y_test).round(4)\n",
    "rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = rf_default_fit_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'         : 'Random Forest',\n",
    "                           'Training Accuracy'  : rf_train_acc,\n",
    "                           'Testing Accuracy'   : rf_test_acc,\n",
    "                           'AUC Score'          : rf_auc,\n",
    "                           'Confusion Matrix'   : (rf_tn,\n",
    "                                                   rf_fp,\n",
    "                                                   rf_fn,\n",
    "                                                   rf_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# FITTING the training data\n",
    "#rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "#rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "#estimator_space  = pd.np.arange(100, 1100, 250)\n",
    "#leaf_space       = pd.np.arange(1, 31, 10)\n",
    "#criterion_space  = ['gini', 'entropy']\n",
    "#bootstrap_space  = [True, False]\n",
    "#warm_start_space = [True, False]\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'n_estimators'     : estimator_space,\n",
    "#              'min_samples_leaf' : leaf_space,\n",
    "#              'criterion'        : criterion_space,\n",
    "#              'bootstrap'        : bootstrap_space,\n",
    " #             'warm_start'       : warm_start_space}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#forest_grid = RandomForestClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "#forest_cv = RandomizedSearchCV(estimator           = forest_grid,\n",
    "#                               param_distributions = param_grid,\n",
    "#                               cv         = 3,\n",
    "#                              n_iter     = 1000,\n",
    "#                              scoring    = make_scorer(roc_auc_score,\n",
    "#                                           needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#forest_cv.fit(chef_class_data, chef_class_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", forest_cv.best_params_)\n",
    "#print(\"Tuned Training AUC:\", forest_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Tuned Training ACCURACY: 0.782\n",
      "Forest Tuned Testing  ACCURACY: 0.8008\n",
      "Forest Tuned AUC Score        : 0.7281\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# copy/pasting in the best_estimator_ results\n",
    "# to avoid running another RandomizedSearch\n",
    "forest_tuned = RandomForestClassifier(bootstrap=False,\n",
    "                       criterion='gini', \n",
    "                       min_samples_leaf=11,\n",
    "                       n_estimators=850,\n",
    "                       random_state=219,\n",
    "                       warm_start=True,\n",
    "                       ccp_alpha=0.0, \n",
    "                       class_weight=None,\n",
    "                       max_depth=None, \n",
    "                       max_features='auto',\n",
    "                       max_leaf_nodes=None,\n",
    "                       max_samples=None,\n",
    "                       min_impurity_decrease=0.0, \n",
    "                       min_impurity_split=None,\n",
    "                       min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0,\n",
    "                       n_jobs=None, oob_score=False, \n",
    "                       verbose=0)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "forest_tuned_fit = forest_tuned.fit(chef_class_data, chef_class_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "forest_tuned_pred = forest_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Forest Tuned Training ACCURACY:', forest_tuned.score(x_train, y_train).round(4))\n",
    "print('Forest Tuned Testing  ACCURACY:', forest_tuned.score(x_test, y_test).round(4))\n",
    "print('Forest Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                                      y_score = forest_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "forest_tuned_train_score = forest_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "forest_tuned_test_score  = forest_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "forest_tuned_auc = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = forest_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting feature importances\n",
    "#plot_feature_importances(forest_tuned_fit,\n",
    " #                        train = x_train,\n",
    " #                        export = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 82\n",
      "False Positives: 74\n",
      "False Negatives: 23\n",
      "True Positives : 308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_rf_tn, \\\n",
    "tuned_rf_fp, \\\n",
    "tuned_rf_fn, \\\n",
    "tuned_rf_tp = confusion_matrix(y_true = y_test, y_pred = forest_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_rf_tn}\n",
    "False Positives: {tuned_rf_fp}\n",
    "False Negatives: {tuned_rf_fn}\n",
    "True Positives : {tuned_rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6794</td>\n",
       "      <td>0.7608</td>\n",
       "      <td>0.7577</td>\n",
       "      <td>(72, 84, 34, 297)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6657</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>(88, 68, 77, 254)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>0.7721</td>\n",
       "      <td>(87, 69, 42, 289)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.6969</td>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>(77, 79, 33, 298)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree(FINAL MODEL)</td>\n",
       "      <td>0.7545</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>(94, 62, 31, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>(81, 75, 47, 284)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tuned Random Forest</td>\n",
       "      <td>0.7281</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.8008</td>\n",
       "      <td>(82, 74, 23, 308)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0                 Logistic     0.6794             0.7608            0.7577  (72, 84, 34, 297)\n",
       "1                Full Tree     0.6657             0.9232            0.7023  (88, 68, 77, 254)\n",
       "2              Pruned Tree     0.7154             0.7526            0.7721  (87, 69, 42, 289)\n",
       "3                 Tuned LR     0.6969             0.7587            0.7700  (77, 79, 33, 298)\n",
       "4  Tuned Tree(FINAL MODEL)     0.7545             0.7656            0.8090  (94, 62, 31, 300)\n",
       "5            Random Forest     0.6886             0.9232            0.7495  (81, 75, 47, 284)\n",
       "6      Tuned Random Forest     0.7281             0.7820            0.8008  (82, 74, 23, 308)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "tuned_rf_train_acc = forest_tuned_fit.score(x_train, y_train).round(4)\n",
    "tuned_rf_test_acc  = forest_tuned_fit.score(x_test, y_test).round(4)\n",
    "tuned_rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                                   y_score = forest_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'         : 'Tuned Random Forest',\n",
    "                           'Training Accuracy'  : tuned_rf_train_acc,\n",
    "                           'Testing Accuracy'   : tuned_rf_test_acc,\n",
    "                           'AUC Score'          : tuned_rf_auc,\n",
    "                           'Confusion Matrix'   : (tuned_rf_tn,\n",
    "                                                   tuned_rf_fp,\n",
    "                                                   tuned_rf_fn,\n",
    "                                                   tuned_rf_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7896\n",
      "Testing ACCURACY : 0.77\n",
      "AUC Score        : 0.702\n"
     ]
    }
   ],
   "source": [
    "#GBM\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "full_gbm_default = GradientBoostingClassifier(loss          = 'deviance',\n",
    "                                              learning_rate = 0.1,\n",
    "                                              n_estimators  = 100,\n",
    "                                              criterion     = 'friedman_mse',\n",
    "                                              max_depth     = 3,\n",
    "                                              warm_start    = False,\n",
    "                                              random_state  = 219)\n",
    "\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "full_gbm_default_fit = full_gbm_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "full_gbm_default_pred = full_gbm_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', full_gbm_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing ACCURACY :', full_gbm_default_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_gbm_default_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 80\n",
      "False Positives: 76\n",
      "False Negatives: 36\n",
      "True Positives : 295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_default_tn, \\\n",
    "gbm_default_fp, \\\n",
    "gbm_default_fn, \\\n",
    "gbm_default_tp = confusion_matrix(y_true = y_test, y_pred = full_gbm_default_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_default_tn}\n",
    "False Positives: {gbm_default_fp}\n",
    "False Negatives: {gbm_default_fn}\n",
    "True Positives : {gbm_default_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6794</td>\n",
       "      <td>0.7608</td>\n",
       "      <td>0.7577</td>\n",
       "      <td>(72, 84, 34, 297)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6657</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>(88, 68, 77, 254)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>0.7721</td>\n",
       "      <td>(87, 69, 42, 289)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.6969</td>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>(77, 79, 33, 298)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree(FINAL MODEL)</td>\n",
       "      <td>0.7545</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>(94, 62, 31, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>(81, 75, 47, 284)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tuned Random Forest</td>\n",
       "      <td>0.7281</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.8008</td>\n",
       "      <td>(82, 74, 23, 308)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBM (Logit_sig6)</td>\n",
       "      <td>0.7020</td>\n",
       "      <td>0.7896</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>(80, 76, 36, 295)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0                 Logistic     0.6794             0.7608            0.7577  (72, 84, 34, 297)\n",
       "1                Full Tree     0.6657             0.9232            0.7023  (88, 68, 77, 254)\n",
       "2              Pruned Tree     0.7154             0.7526            0.7721  (87, 69, 42, 289)\n",
       "3                 Tuned LR     0.6969             0.7587            0.7700  (77, 79, 33, 298)\n",
       "4  Tuned Tree(FINAL MODEL)     0.7545             0.7656            0.8090  (94, 62, 31, 300)\n",
       "5            Random Forest     0.6886             0.9232            0.7495  (81, 75, 47, 284)\n",
       "6      Tuned Random Forest     0.7281             0.7820            0.8008  (82, 74, 23, 308)\n",
       "7         GBM (Logit_sig6)     0.7020             0.7896            0.7700  (80, 76, 36, 295)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "gbm_train_acc = full_gbm_default_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_acc  = full_gbm_default_fit.score(x_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = full_gbm_default_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'       : 'GBM (Logit_sig6)',\n",
    "                          'Training Accuracy' : gbm_train_acc,\n",
    "                          'Testing Accuracy'  : gbm_test_acc,\n",
    "                          'AUC Score'         : gbm_auc,\n",
    "                          'Confusion Matrix'  : (gbm_default_tn,\n",
    "                                                 gbm_default_fp,\n",
    "                                                 gbm_default_fn,\n",
    "                                                 gbm_default_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# declaring a hyperparameter space\n",
    "#learn_space        = pd.np.arange(0.1, 2.0, 0.2)\n",
    "#estimator_space    = pd.np.arange(100, 200, 25)\n",
    "#depth_space        = pd.np.arange(1, 20, 2)\n",
    "#warm_start_space   = [True, False]\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'learning_rate' : learn_space,\n",
    "#              'max_depth'     : depth_space,\n",
    "#              'n_estimators'  : estimator_space,\n",
    "#              'warm_start'     : warm_start_space}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#full_gbm_grid = GradientBoostingClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "#full_gbm_cv = RandomizedSearchCV(estimator     = full_gbm_grid,\n",
    "#                           param_distributions = param_grid,\n",
    "#                           cv                  = 3,\n",
    "#                           n_iter              = 500,\n",
    "#                          random_state        = 219,\n",
    "#                           scoring             = make_scorer(roc_auc_score,\n",
    "#                                                 needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#full_gbm_cv.fit(chef_class_data, chef_class_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", full_gbm_cv.best_params_)\n",
    "#print(\"Tuned Training AUC:\", full_gbm_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.769\n",
      "Testing  ACCURACY: 0.7988\n",
      "AUC Score        : 0.735\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING the model object without hyperparameters\n",
    "\n",
    "# I made several attempts to hyperparameter tuning\n",
    "gbm_tuned = GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
    "                           learning_rate=0.7000000000000001, loss='deviance',\n",
    "                           max_depth=1, max_features=None, max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=250,\n",
    "                           n_iter_no_change=None, \n",
    "                           random_state=219,\n",
    "                           warm_start=True)\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "gbm_tuned_fit = gbm_tuned.fit(chef_class_data, chef_class_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "gbm_tuned_pred = gbm_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', gbm_tuned_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', gbm_tuned_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = gbm_tuned_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 87\n",
      "False Positives: 69\n",
      "False Negatives: 29\n",
      "True Positives : 302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_tuned_tn, \\\n",
    "gbm_tuned_fp, \\\n",
    "gbm_tuned_fn, \\\n",
    "gbm_tuned_tp = confusion_matrix(y_true = y_test, y_pred = gbm_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_tuned_tn}\n",
    "False Positives: {gbm_tuned_fp}\n",
    "False Negatives: {gbm_tuned_fn}\n",
    "True Positives : {gbm_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6794</td>\n",
       "      <td>0.7608</td>\n",
       "      <td>0.7577</td>\n",
       "      <td>(72, 84, 34, 297)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6657</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>(88, 68, 77, 254)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>0.7721</td>\n",
       "      <td>(87, 69, 42, 289)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.6969</td>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>(77, 79, 33, 298)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree(FINAL MODEL)</td>\n",
       "      <td>0.7545</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>(94, 62, 31, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>(81, 75, 47, 284)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tuned Random Forest</td>\n",
       "      <td>0.7281</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.8008</td>\n",
       "      <td>(82, 74, 23, 308)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBM (Logit_sig6)</td>\n",
       "      <td>0.7020</td>\n",
       "      <td>0.7896</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>(80, 76, 36, 295)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tuned GBM</td>\n",
       "      <td>0.7350</td>\n",
       "      <td>0.7690</td>\n",
       "      <td>0.7988</td>\n",
       "      <td>(87, 69, 29, 302)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0                 Logistic     0.6794             0.7608            0.7577  (72, 84, 34, 297)\n",
       "1                Full Tree     0.6657             0.9232            0.7023  (88, 68, 77, 254)\n",
       "2              Pruned Tree     0.7154             0.7526            0.7721  (87, 69, 42, 289)\n",
       "3                 Tuned LR     0.6969             0.7587            0.7700  (77, 79, 33, 298)\n",
       "4  Tuned Tree(FINAL MODEL)     0.7545             0.7656            0.8090  (94, 62, 31, 300)\n",
       "5            Random Forest     0.6886             0.9232            0.7495  (81, 75, 47, 284)\n",
       "6      Tuned Random Forest     0.7281             0.7820            0.8008  (82, 74, 23, 308)\n",
       "7         GBM (Logit_sig6)     0.7020             0.7896            0.7700  (80, 76, 36, 295)\n",
       "8                Tuned GBM     0.7350             0.7690            0.7988  (87, 69, 29, 302)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "gbm_train_acc = gbm_tuned_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_acc  = gbm_tuned_fit.score(x_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = gbm_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned GBM',\n",
    "                          'Training Accuracy'  : gbm_train_acc,\n",
    "                          'Testing Accuracy'   : gbm_test_acc,\n",
    "                          'AUC Score'          : gbm_auc,\n",
    "                          'Confusion Matrix'   : (gbm_tuned_tn,\n",
    "                                                  gbm_tuned_fp,\n",
    "                                                  gbm_tuned_fn,\n",
    "                                                  gbm_tuned_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree(FINAL MODEL)</td>\n",
       "      <td>0.7545</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>(94, 62, 31, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tuned GBM</td>\n",
       "      <td>0.7350</td>\n",
       "      <td>0.7690</td>\n",
       "      <td>0.7988</td>\n",
       "      <td>(87, 69, 29, 302)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tuned Random Forest</td>\n",
       "      <td>0.7281</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.8008</td>\n",
       "      <td>(82, 74, 23, 308)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>0.7721</td>\n",
       "      <td>(87, 69, 42, 289)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBM (Logit_sig6)</td>\n",
       "      <td>0.7020</td>\n",
       "      <td>0.7896</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>(80, 76, 36, 295)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.6969</td>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>(77, 79, 33, 298)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>(81, 75, 47, 284)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6794</td>\n",
       "      <td>0.7608</td>\n",
       "      <td>0.7577</td>\n",
       "      <td>(72, 84, 34, 297)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6657</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>(88, 68, 77, 254)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "4  Tuned Tree(FINAL MODEL)     0.7545             0.7656            0.8090  (94, 62, 31, 300)\n",
       "8                Tuned GBM     0.7350             0.7690            0.7988  (87, 69, 29, 302)\n",
       "6      Tuned Random Forest     0.7281             0.7820            0.8008  (82, 74, 23, 308)\n",
       "2              Pruned Tree     0.7154             0.7526            0.7721  (87, 69, 42, 289)\n",
       "7         GBM (Logit_sig6)     0.7020             0.7896            0.7700  (80, 76, 36, 295)\n",
       "3                 Tuned LR     0.6969             0.7587            0.7700  (77, 79, 33, 298)\n",
       "5            Random Forest     0.6886             0.9232            0.7495  (81, 75, 47, 284)\n",
       "0                 Logistic     0.6794             0.7608            0.7577  (72, 84, 34, 297)\n",
       "1                Full Tree     0.6657             0.9232            0.7023  (88, 68, 77, 254)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance.sort_values(by = 'AUC Score',\n",
    "                              ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# saving the DataFrame to Excel\n",
    "model_performance.to_excel('./classification_model_performance.xlsx',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
