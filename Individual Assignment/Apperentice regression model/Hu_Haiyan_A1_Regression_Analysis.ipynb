{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"mark\">\n",
    "Part I: FEATURE ENGINEERING AND MODEL PREPARATION</div><i class=\"fa fa-lightbulb-o \"></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP 1- importing packages and loading data.\n",
    "\n",
    "# importing libraries\n",
    "import pandas as pd # data science essentials\n",
    "import matplotlib.pyplot as plt # essential graphical output\n",
    "import seaborn as sns # enhanced graphical output\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "# specifying file name\n",
    "file = './Apprentice_Chef_Dataset.xlsx'\n",
    "\n",
    "\n",
    "# reading the file into Python\n",
    "chef = pd.read_excel(io=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saathos</td>\n",
       "      <td>unitedhealth.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alysanne.osgrey</td>\n",
       "      <td>ge.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edwyd.fossoway</td>\n",
       "      <td>jnj.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eleyna.westerling</td>\n",
       "      <td>ge.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>elyn.norridge</td>\n",
       "      <td>jnj.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>obara.sand</td>\n",
       "      <td>yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>quentyn.blackwood</td>\n",
       "      <td>yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>rhonda.rowan</td>\n",
       "      <td>gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>turnip</td>\n",
       "      <td>yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>tommard.heddle</td>\n",
       "      <td>merck.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1946 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0                 1\n",
       "0               saathos  unitedhealth.com\n",
       "1       alysanne.osgrey            ge.org\n",
       "2        edwyd.fossoway           jnj.com\n",
       "3     eleyna.westerling            ge.org\n",
       "4         elyn.norridge           jnj.com\n",
       "...                 ...               ...\n",
       "1941         obara.sand         yahoo.com\n",
       "1942  quentyn.blackwood         yahoo.com\n",
       "1943       rhonda.rowan         gmail.com\n",
       "1944             turnip         yahoo.com\n",
       "1945     tommard.heddle         merck.com\n",
       "\n",
       "[1946 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STEP 2, feature engineering emails.\n",
    "\n",
    "#Using EMAIL to get the domain out and then catogorize the email domains\n",
    "# step a\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in chef.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "    split_email = chef.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "\n",
    "# converting placeholder_lst into a DataFrame \n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "# displaying the results\n",
    "email_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unitedhealth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ge.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jnj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ge.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jnj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>yahoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>yahoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>gmail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>yahoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>merck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1946 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "0     unitedhealth\n",
       "1           ge.org\n",
       "2              jnj\n",
       "3           ge.org\n",
       "4              jnj\n",
       "...            ...\n",
       "1941         yahoo\n",
       "1942         yahoo\n",
       "1943         gmail\n",
       "1944         yahoo\n",
       "1945         merck\n",
       "\n",
       "[1946 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step b: remove \".com\" from domains\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in email_df.iterrows():\n",
    "    \n",
    "    \n",
    "    replace_email = email_df.iloc[index, 1].replace('.com','')\n",
    "\n",
    "    placeholder_lst.append(replace_email)\n",
    "    \n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "# displaying the results\n",
    "email_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>EMAIL_domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unitedhealth</td>\n",
       "      <td>unitedhealth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ge</td>\n",
       "      <td>ge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jnj</td>\n",
       "      <td>jnj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ge</td>\n",
       "      <td>ge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jnj</td>\n",
       "      <td>jnj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0  EMAIL_domain\n",
       "0  unitedhealth  unitedhealth\n",
       "1            ge            ge\n",
       "2           jnj           jnj\n",
       "3            ge            ge\n",
       "4           jnj           jnj"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step c, removing \".org\" in domains\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in email_df.iterrows():\n",
    "    \n",
    "    \n",
    "    replace_email = email_df.iloc[index, 0].replace('.org','')\n",
    "  \n",
    "    placeholder_lst.append(replace_email)\n",
    "    \n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "# displaying the results\n",
    "\n",
    "email_df\n",
    "email_df['EMAIL_domain']=email_df.iloc[:,0]\n",
    "email_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP d: concatenating with original DataFrame\n",
    "\n",
    "# safety measure in case of multiple concatenations\n",
    "chef = pd.read_excel(file)\n",
    "\n",
    "\n",
    "# renaming column to concatenate\n",
    "email_df.columns = [\"0\" , \"EMAIL_domain\"]\n",
    "\n",
    "\n",
    "# concatenating personal_email_domain with friends DataFrame\n",
    "chef = pd.concat([chef, email_df[\"EMAIL_domain\"]],\n",
    "                   axis = 1)\n",
    "\n",
    "\n",
    "# printing value counts of personal_email_domain\n",
    "#chef.loc[: ,'EMAIL_domain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "personal    1250\n",
       "business     696\n",
       "Name: DOMAIN_group, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP e: Categorize email domains to personal and business\n",
    "personal_email_domains = ['gmail', 'protonmail','yahoo','msn',\n",
    "                         'aol','passport','hotmail','live','me']\n",
    "business_email_domains  = ['homedepot','intel','unitedtech','cisco','goldmansacs',\n",
    "                              'jpmorgan','visa','pfizer','disney','walmart','unitedhealth',\n",
    "'boeing','caterpillar','verizon','pg','dupont','ibm','chevron','microsoft', \n",
    "'travelers','exxon','amex','cocacola','mcdonalds','merck','jnj','apple','nike',          \n",
    "'ge','mmm']\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "\n",
    "# looping to group observations by domain type\n",
    "for domain in chef['EMAIL_domain']:\n",
    "    \n",
    "    if domain in personal_email_domains:\n",
    "        placeholder_lst.append('personal')\n",
    "        \n",
    "\n",
    "    elif domain in business_email_domains:\n",
    "        placeholder_lst.append('business')\n",
    "\n",
    "\n",
    "    else:\n",
    "            print('Unknown')\n",
    "\n",
    "\n",
    "# concatenating with original DataFrame\n",
    "chef['DOMAIN_group'] = pd.Series(placeholder_lst)\n",
    "\n",
    "\n",
    "# checking results\n",
    "chef['DOMAIN_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP f, creating \"EMAIL_type\" column, # 1 for personal email, 0 for business.\n",
    "chef['EMAIL_type']   = 0\n",
    "\n",
    "\n",
    "\n",
    "for index, value in chef.iterrows():\n",
    "    \n",
    "   \n",
    "    if chef.loc[index, 'DOMAIN_group'] == 'business':\n",
    "        chef.loc[index, 'EMAIL_type'] = 0\n",
    "\n",
    "    else: \n",
    "        chef.loc[index, 'EMAIL_type'] = 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP g, Getting dummy variables from catogory variable\"EMAIL_domain\"\n",
    "# one hot encoding categorical variables\n",
    "one_hot_email       = pd.get_dummies(chef['EMAIL_domain'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# joining codings together\n",
    "chef = chef.join([one_hot_email])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# dropping \"NAME\",\"EMAIL\", \"FIRST_NAME\", \"FAMILY_NAME\",\"EMAIL_DOMAIN\", AND\n",
    "#\"DOMAIN_group\" from model development.\n",
    "\n",
    "chef = chef.drop('NAME', axis = 1) # can't run more than one time\n",
    "chef = chef.drop('EMAIL', axis = 1)\n",
    "chef = chef.drop('FIRST_NAME', axis = 1)\n",
    "chef= chef.drop('FAMILY_NAME', axis = 1)\n",
    "chef = chef.drop('EMAIL_domain', axis = 1)\n",
    "chef = chef.drop('DOMAIN_group', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# renaming misleading column and create a \"log_AVG_ORDER_SIZE\"\n",
    "chef=chef.rename({'LARGEST_ORDER_SIZE':'AVG_ORDER_SIZE'}, axis=1)\n",
    "chef[\"log_AVG_ORDER_SIZE\"]=np.log10(chef.loc[:,\"AVG_ORDER_SIZE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP 3, log transforming\n",
    "\n",
    "chef['log_REVENUE'] = np.log10(chef['REVENUE'])\n",
    "chef['log_AVG_TIME_PER_SITE_VISIT'] = np.log10(chef['AVG_TIME_PER_SITE_VISIT'])\n",
    "chef['log_AVG_PREP_VID_TIME']=np.log10(chef['AVG_PREP_VID_TIME'])\n",
    "chef['log_TOTAL_MEALS_ORDERED'] = np.log10(chef['TOTAL_MEALS_ORDERED'])\n",
    "chef['log_UNIQUE_MEALS_PURCH'] = np.log10(chef.loc[:, 'UNIQUE_MEALS_PURCH'])\n",
    "chef[\"log_CONTACTS_W_CUSTOMER_SERVICE\"]=np.log10(chef.loc[:,\"CONTACTS_W_CUSTOMER_SERVICE\"])\n",
    "chef['log_PRODUCT_CATEGORIES_VIEWED']=np.log10(chef.loc[:,\"PRODUCT_CATEGORIES_VIEWED\"])\n",
    "chef[\"log_AVG_CLICKS_PER_VISIT\"]=np.log10(chef.loc[:,\"AVG_CLICKS_PER_VISIT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP 4, creating binary if counts of 0s is greater than 100.\n",
    "chef['has_WEEKLY_PLAN']   = 0\n",
    "chef['has_VIEWED_PHOTOS'] = 0\n",
    "chef['has_EARLY_DELIVERIES'] = 0\n",
    "chef['has_LATE_DELIVERIES'] = 0\n",
    "chef['has_MASTER_CLASSES_ATTENDED'] = 0\n",
    "\n",
    "for index, value in chef.iterrows():\n",
    "    \n",
    "    # Total_Bsmt_SF\n",
    "    if chef.loc[index, 'WEEKLY_PLAN'] > 0:\n",
    "        chef.loc[index, 'has_WEEKLY_PLAN'] = 1\n",
    "\n",
    "\n",
    "    if chef.loc[index, 'TOTAL_PHOTOS_VIEWED'] > 0:\n",
    "        chef.loc[index, 'has_VIEWED_PHOTOS'] = 1\n",
    "            # Total_Bsmt_SF\n",
    "    if chef.loc[index, 'EARLY_DELIVERIES'] > 0:\n",
    "        chef.loc[index, 'has_EARLY_DELIVERIES'] = 1\n",
    "\n",
    "\n",
    "    if chef.loc[index, 'LATE_DELIVERIES'] > 0:\n",
    "        chef.loc[index, 'has_LATE_DELIVERIES'] = 1\n",
    "        \n",
    "    if chef.loc[index, 'MASTER_CLASSES_ATTENDED'] > 0:\n",
    "        chef.loc[index, 'has_MASTER_CLASSES_ATTENDED'] = 1   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS_SELL_SUCCESS +\n",
      "TOTAL_MEALS_ORDERED +\n",
      "UNIQUE_MEALS_PURCH +\n",
      "CONTACTS_W_CUSTOMER_SERVICE +\n",
      "PRODUCT_CATEGORIES_VIEWED +\n",
      "AVG_TIME_PER_SITE_VISIT +\n",
      "MOBILE_NUMBER +\n",
      "CANCELLATIONS_BEFORE_NOON +\n",
      "CANCELLATIONS_AFTER_NOON +\n",
      "TASTES_AND_PREFERENCES +\n",
      "PC_LOGINS +\n",
      "MOBILE_LOGINS +\n",
      "WEEKLY_PLAN +\n",
      "EARLY_DELIVERIES +\n",
      "LATE_DELIVERIES +\n",
      "PACKAGE_LOCKER +\n",
      "REFRIGERATED_LOCKER +\n",
      "AVG_PREP_VID_TIME +\n",
      "AVG_ORDER_SIZE +\n",
      "MASTER_CLASSES_ATTENDED +\n",
      "MEDIAN_MEAL_RATING +\n",
      "AVG_CLICKS_PER_VISIT +\n",
      "TOTAL_PHOTOS_VIEWED +\n",
      "EMAIL_type +\n",
      "amex +\n",
      "aol +\n",
      "apple +\n",
      "boeing +\n",
      "caterpillar +\n",
      "chevron +\n",
      "cisco +\n",
      "cocacola +\n",
      "disney +\n",
      "dupont +\n",
      "exxon +\n",
      "ge +\n",
      "gmail +\n",
      "goldmansacs +\n",
      "homedepot +\n",
      "hotmail +\n",
      "ibm +\n",
      "intel +\n",
      "jnj +\n",
      "jpmorgan +\n",
      "live +\n",
      "mcdonalds +\n",
      "me +\n",
      "merck +\n",
      "microsoft +\n",
      "mmm +\n",
      "msn +\n",
      "nike +\n",
      "passport +\n",
      "pfizer +\n",
      "pg +\n",
      "protonmail +\n",
      "travelers +\n",
      "unitedhealth +\n",
      "unitedtech +\n",
      "verizon +\n",
      "visa +\n",
      "walmart +\n",
      "yahoo +\n",
      "log_AVG_ORDER_SIZE +\n",
      "log_AVG_TIME_PER_SITE_VISIT +\n",
      "log_AVG_PREP_VID_TIME +\n",
      "log_TOTAL_MEALS_ORDERED +\n",
      "log_UNIQUE_MEALS_PURCH +\n",
      "log_CONTACTS_W_CUSTOMER_SERVICE +\n",
      "log_PRODUCT_CATEGORIES_VIEWED +\n",
      "log_AVG_CLICKS_PER_VISIT +\n",
      "has_WEEKLY_PLAN +\n",
      "has_VIEWED_PHOTOS +\n",
      "has_EARLY_DELIVERIES +\n",
      "has_LATE_DELIVERIES +\n",
      "has_MASTER_CLASSES_ATTENDED +\n"
     ]
    }
   ],
   "source": [
    "# STEP6,\n",
    "#making a copy of chef\n",
    "chef_explanatory = chef.copy()\n",
    "\n",
    "\n",
    "# dropping REVENUE,log_REVENUE,NAME, FIRST_NAME, FAMILY_NAME, and EMAIL from the explanatory variable set\n",
    "chef_explanatory = chef_explanatory.drop(['REVENUE',\n",
    "                                        'log_REVENUE'], axis = 1)\n",
    "\n",
    "\n",
    "# formatting each explanatory variable for statsmodels\n",
    "for val in chef_explanatory:\n",
    "    print(f\"{val} +\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP 7, \n",
    "# saving engineered dataset in Excel\n",
    "chef.to_excel('./chef_ready.xlsx',\n",
    "                 index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>log_REVENUE</td>   <th>  R-squared:         </th> <td>   0.729</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   371.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 05 Jul 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:13:58</td>     <th>  Log-Likelihood:    </th> <td>  1531.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1946</td>      <th>  AIC:               </th> <td>  -3032.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1931</td>      <th>  BIC:               </th> <td>  -2948.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>    1.4645</td> <td>    0.062</td> <td>   23.781</td> <td> 0.000</td> <td>    1.344</td> <td>    1.585</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CROSS_SELL_SUCCESS</th>              <td>   -0.0127</td> <td>    0.005</td> <td>   -2.354</td> <td> 0.019</td> <td>   -0.023</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PRODUCT_CATEGORIES_VIEWED</th>       <td>    0.0020</td> <td>    0.001</td> <td>    2.393</td> <td> 0.017</td> <td>    0.000</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TASTES_AND_PREFERENCES</th>          <td>    0.0120</td> <td>    0.006</td> <td>    2.142</td> <td> 0.032</td> <td>    0.001</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MASTER_CLASSES_ATTENDED</th>         <td>    0.0278</td> <td>    0.005</td> <td>    6.064</td> <td> 0.000</td> <td>    0.019</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MEDIAN_MEAL_RATING</th>              <td>    0.0646</td> <td>    0.004</td> <td>   14.944</td> <td> 0.000</td> <td>    0.056</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TOTAL_PHOTOS_VIEWED</th>             <td> 5.516e-05</td> <td> 2.04e-05</td> <td>    2.707</td> <td> 0.007</td> <td> 1.52e-05</td> <td> 9.51e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yahoo</th>                           <td>    0.0210</td> <td>    0.007</td> <td>    2.904</td> <td> 0.004</td> <td>    0.007</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_AVG_ORDER_SIZE</th>              <td>   -0.1455</td> <td>    0.026</td> <td>   -5.493</td> <td> 0.000</td> <td>   -0.197</td> <td>   -0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_AVG_PREP_VID_TIME</th>           <td>    0.5660</td> <td>    0.036</td> <td>   15.539</td> <td> 0.000</td> <td>    0.495</td> <td>    0.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_TOTAL_MEALS_ORDERED</th>         <td>    0.2575</td> <td>    0.011</td> <td>   23.372</td> <td> 0.000</td> <td>    0.236</td> <td>    0.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_UNIQUE_MEALS_PURCH</th>          <td>   -0.1647</td> <td>    0.009</td> <td>  -17.758</td> <td> 0.000</td> <td>   -0.183</td> <td>   -0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_CONTACTS_W_CUSTOMER_SERVICE</th> <td>    0.1315</td> <td>    0.018</td> <td>    7.119</td> <td> 0.000</td> <td>    0.095</td> <td>    0.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_WEEKLY_PLAN</th>                 <td>   -0.0126</td> <td>    0.006</td> <td>   -2.151</td> <td> 0.032</td> <td>   -0.024</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_VIEWED_PHOTOS</th>               <td>    0.0200</td> <td>    0.007</td> <td>    2.740</td> <td> 0.006</td> <td>    0.006</td> <td>    0.034</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>229.218</td> <th>  Durbin-Watson:     </th> <td>   2.060</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 930.906</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.513</td>  <th>  Prob(JB):          </th> <td>7.18e-203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.229</td>  <th>  Cond. No.          </th> <td>6.08e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.08e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            log_REVENUE   R-squared:                       0.729\n",
       "Model:                            OLS   Adj. R-squared:                  0.727\n",
       "Method:                 Least Squares   F-statistic:                     371.5\n",
       "Date:                Mon, 05 Jul 2021   Prob (F-statistic):               0.00\n",
       "Time:                        10:13:58   Log-Likelihood:                 1531.0\n",
       "No. Observations:                1946   AIC:                            -3032.\n",
       "Df Residuals:                    1931   BIC:                            -2948.\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                           1.4645      0.062     23.781      0.000       1.344       1.585\n",
       "CROSS_SELL_SUCCESS                 -0.0127      0.005     -2.354      0.019      -0.023      -0.002\n",
       "PRODUCT_CATEGORIES_VIEWED           0.0020      0.001      2.393      0.017       0.000       0.004\n",
       "TASTES_AND_PREFERENCES              0.0120      0.006      2.142      0.032       0.001       0.023\n",
       "MASTER_CLASSES_ATTENDED             0.0278      0.005      6.064      0.000       0.019       0.037\n",
       "MEDIAN_MEAL_RATING                  0.0646      0.004     14.944      0.000       0.056       0.073\n",
       "TOTAL_PHOTOS_VIEWED              5.516e-05   2.04e-05      2.707      0.007    1.52e-05    9.51e-05\n",
       "yahoo                               0.0210      0.007      2.904      0.004       0.007       0.035\n",
       "log_AVG_ORDER_SIZE                 -0.1455      0.026     -5.493      0.000      -0.197      -0.094\n",
       "log_AVG_PREP_VID_TIME               0.5660      0.036     15.539      0.000       0.495       0.637\n",
       "log_TOTAL_MEALS_ORDERED             0.2575      0.011     23.372      0.000       0.236       0.279\n",
       "log_UNIQUE_MEALS_PURCH             -0.1647      0.009    -17.758      0.000      -0.183      -0.147\n",
       "log_CONTACTS_W_CUSTOMER_SERVICE     0.1315      0.018      7.119      0.000       0.095       0.168\n",
       "has_WEEKLY_PLAN                    -0.0126      0.006     -2.151      0.032      -0.024      -0.001\n",
       "has_VIEWED_PHOTOS                   0.0200      0.007      2.740      0.006       0.006       0.034\n",
       "==============================================================================\n",
       "Omnibus:                      229.218   Durbin-Watson:                   2.060\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              930.906\n",
       "Skew:                          -0.513   Prob(JB):                    7.18e-203\n",
       "Kurtosis:                       6.229   Cond. No.                     6.08e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.08e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 8-1,building a full model WITH log_REVENUE\n",
    "\n",
    "# blueprinting a model type\n",
    "lm_full = smf.ols(formula = \"\"\"log_REVENUE ~ CROSS_SELL_SUCCESS +\n",
    "PRODUCT_CATEGORIES_VIEWED +\n",
    "TASTES_AND_PREFERENCES +\n",
    "MASTER_CLASSES_ATTENDED +\n",
    "MEDIAN_MEAL_RATING +\n",
    "TOTAL_PHOTOS_VIEWED +\n",
    "yahoo +\n",
    "log_AVG_ORDER_SIZE +\n",
    "log_AVG_PREP_VID_TIME +\n",
    "log_TOTAL_MEALS_ORDERED +\n",
    "log_UNIQUE_MEALS_PURCH +\n",
    "log_CONTACTS_W_CUSTOMER_SERVICE +\n",
    "has_WEEKLY_PLAN +\n",
    "has_VIEWED_PHOTOS \n",
    "\"\"\",\n",
    "                               data = chef)\n",
    "\n",
    "\n",
    "# telling Python to run the data through the blueprint\n",
    "results_full = lm_full.fit()\n",
    "\n",
    "\n",
    "# printing the results\n",
    "results_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP 8-2,building a full model with REVENUE,\n",
    "\n",
    "# blueprinting a model type\n",
    "#lm_full = smf.ols(formula = \"\"\"REVENUE ~ CROSS_SELL_SUCCESS +\n",
    "\n",
    "#CONTACTS_W_CUSTOMER_SERVICE +\n",
    "#AVG_PREP_VID_TIME +\n",
    "#AVG_ORDER_SIZE +\n",
    "#MASTER_CLASSES_ATTENDED +\n",
    "#MEDIAN_MEAL_RATING +\n",
    "#AVG_CLICKS_PER_VISIT +\n",
    "#TOTAL_PHOTOS_VIEWED +\n",
    "#unitedhealth +\n",
    "#yahoo +\n",
    "#log_TOTAL_MEALS_ORDERED +\n",
    "#log_UNIQUE_MEALS_PURCH +\n",
    "#log_AVG_CLICKS_PER_VISIT  \"\"\",\n",
    "#data = chef)\n",
    "\n",
    "\n",
    "# telling Python to run the data through the blueprint\n",
    "#results_full = lm_full.fit()\n",
    "\n",
    "\n",
    "# printing the results\n",
    "#results_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#df_corr = chef.corr().round(2)\n",
    "\n",
    "\n",
    "# printing (Pearson) correlations with SalePrice\n",
    "#print(df_corr.loc['log_REVENUE'].sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"mark\">PART II- MODEL TOURNAMENT</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# importing libraries, importing dataset\n",
    "import pandas as pd # data science essentials\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # enhanced data visualization\n",
    "import statsmodels.formula.api as smf # regression modeling\n",
    "from sklearn.model_selection import train_test_split # train/test split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "# specifying the path and file name\n",
    "file = './chef_ready.xlsx'\n",
    "\n",
    "\n",
    "# reading the file into Python\n",
    "chef_ready = pd.read_excel(file)\n",
    "\n",
    "\n",
    "# checking the file\n",
    "#chef_ready.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data\n",
      "-------------\n",
      "X-side: (1459, 76)\n",
      "y-side: (1459,)\n",
      "\n",
      "\n",
      "Testing Data\n",
      "------------\n",
      "X-side: (487, 76)\n",
      "y-side: (487,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#preparing training and testing datasets\n",
    "\n",
    "# preparing explanatory variable data by dropping \"REVENUE\", and \"log_REVENUE\"\n",
    "chef_ready_data   = chef_ready.drop(['REVENUE',\n",
    "                               'log_REVENUE'],\n",
    "                                axis = 1)\n",
    "\n",
    "# preparing response variable data\n",
    "#chef_ready_target = chef_ready.loc[ : , 'REVENUE']\n",
    "\n",
    "log_chef_ready_target = chef_ready.loc[ : , 'log_REVENUE'] # use log_REVENUE in my assignment\n",
    "\n",
    "\n",
    "# preparing training and testing sets (all letters are lowercase)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            chef_ready_data,\n",
    "            log_chef_ready_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n",
    "\n",
    "\n",
    "# checking the shapes of the datasets\n",
    "print(f\"\"\"\n",
    "Training Data\n",
    "-------------\n",
    "X-side: {x_train.shape}\n",
    "y-side: {y_train.shape}\n",
    "\n",
    "\n",
    "Testing Data\n",
    "------------\n",
    "X-side: {x_test.shape}\n",
    "y-side: {y_test.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS_SELL_SUCCESS +\n",
      "PRODUCT_CATEGORIES_VIEWED +\n",
      "TASTES_AND_PREFERENCES +\n",
      "MEDIAN_MEAL_RATING +\n",
      "TOTAL_PHOTOS_VIEWED +\n",
      "yahoo +\n",
      "log_AVG_PREP_VID_TIME +\n",
      "log_TOTAL_MEALS_ORDERED +\n",
      "AVG_ORDER_SIZE +\n",
      "log_UNIQUE_MEALS_PURCH +\n",
      "log_CONTACTS_W_CUSTOMER_SERVICE +\n",
      "has_MASTER_CLASSES_ATTENDED +\n",
      "has_WEEKLY_PLAN +\n",
      "walmart +\n"
     ]
    }
   ],
   "source": [
    "# declaring set of x-variables\n",
    "x_variables=['CROSS_SELL_SUCCESS',\n",
    "             'PRODUCT_CATEGORIES_VIEWED',\n",
    "'TASTES_AND_PREFERENCES',\n",
    "'MEDIAN_MEAL_RATING' ,\n",
    "'TOTAL_PHOTOS_VIEWED' ,\n",
    "'yahoo',\n",
    "'log_AVG_PREP_VID_TIME',\n",
    "'log_TOTAL_MEALS_ORDERED',\n",
    "'AVG_ORDER_SIZE',\n",
    "'log_UNIQUE_MEALS_PURCH',\n",
    "'log_CONTACTS_W_CUSTOMER_SERVICE',\n",
    "'has_MASTER_CLASSES_ATTENDED',\n",
    "'has_WEEKLY_PLAN',\n",
    "'walmart']\n",
    "for val in x_variables:\n",
    "    print(f\"{val} +\")\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            log_REVENUE   R-squared:                       0.730\n",
      "Model:                            OLS   Adj. R-squared:                  0.727\n",
      "Method:                 Least Squares   F-statistic:                     278.3\n",
      "Date:                Mon, 05 Jul 2021   Prob (F-statistic):               0.00\n",
      "Time:                        10:14:01   Log-Likelihood:                 1165.6\n",
      "No. Observations:                1459   AIC:                            -2301.\n",
      "Df Residuals:                    1444   BIC:                            -2222.\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                           1.5249      0.071     21.423      0.000       1.385       1.665\n",
      "CROSS_SELL_SUCCESS                 -0.0167      0.006     -2.718      0.007      -0.029      -0.005\n",
      "PRODUCT_CATEGORIES_VIEWED           0.0018      0.001      1.958      0.050    -3.6e-06       0.004\n",
      "TASTES_AND_PREFERENCES              0.0145      0.006      2.290      0.022       0.002       0.027\n",
      "MASTER_CLASSES_ATTENDED             0.0281      0.005      5.439      0.000       0.018       0.038\n",
      "MEDIAN_MEAL_RATING                  0.0663      0.005     13.551      0.000       0.057       0.076\n",
      "TOTAL_PHOTOS_VIEWED              8.659e-05   1.79e-05      4.835      0.000    5.15e-05       0.000\n",
      "yahoo                               0.0270      0.008      3.300      0.001       0.011       0.043\n",
      "log_AVG_ORDER_SIZE                 -0.1353      0.031     -4.407      0.000      -0.196      -0.075\n",
      "log_AVG_PREP_VID_TIME               0.5459      0.042     12.988      0.000       0.463       0.628\n",
      "log_TOTAL_MEALS_ORDERED             0.2565      0.013     20.134      0.000       0.231       0.281\n",
      "log_UNIQUE_MEALS_PURCH             -0.1746      0.011    -16.372      0.000      -0.196      -0.154\n",
      "log_CONTACTS_W_CUSTOMER_SERVICE     0.1126      0.021      5.288      0.000       0.071       0.154\n",
      "has_WEEKLY_PLAN                    -0.0148      0.007     -2.218      0.027      -0.028      -0.002\n",
      "walmart                             0.0658      0.030      2.230      0.026       0.008       0.124\n",
      "==============================================================================\n",
      "Omnibus:                      163.205   Durbin-Watson:                   2.056\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              635.512\n",
      "Skew:                          -0.487   Prob(JB):                    1.00e-138\n",
      "Kurtosis:                       6.083   Cond. No.                     6.20e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.2e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# merging X_train and y_train so that they can be used in statsmodels\n",
    "chef_ready_train = pd.concat([x_train, y_train], axis = 1)\n",
    "\n",
    "\n",
    "# Step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"log_REVENUE ~ CROSS_SELL_SUCCESS +\n",
    "PRODUCT_CATEGORIES_VIEWED +\n",
    "TASTES_AND_PREFERENCES +\n",
    "MASTER_CLASSES_ATTENDED +\n",
    "MEDIAN_MEAL_RATING +\n",
    "TOTAL_PHOTOS_VIEWED +\n",
    "yahoo +\n",
    "log_AVG_ORDER_SIZE +\n",
    "log_AVG_PREP_VID_TIME +\n",
    "log_TOTAL_MEALS_ORDERED +\n",
    "log_UNIQUE_MEALS_PURCH +\n",
    "log_CONTACTS_W_CUSTOMER_SERVICE +\n",
    "has_WEEKLY_PLAN +\n",
    "walmart \"\"\",\n",
    "data =chef_ready_train)\n",
    "\n",
    "\n",
    "# Step 2: fit the model based on the data\n",
    "results = lm_best.fit()\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: analyze the summary output\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"girk\">OLS MODEL</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# applying model in scikit-learn \n",
    "\n",
    "# Preparing a DataFrame based the the analysis above\n",
    "ols_data   = chef_ready.loc[ : , x_variables]\n",
    "\n",
    "\n",
    "# Preparing the target variable\n",
    "log_chef_ready_target = chef_ready.loc[ : , 'log_REVENUE']\n",
    "\n",
    "\n",
    "###############################################\n",
    "## setting up more than one train-test split ##\n",
    "###############################################\n",
    "# FULL X-dataset (log Y)\n",
    "x_train_FULL, x_test_FULL, y_train_FULL, y_test_FULL = train_test_split(\n",
    "            chef_ready_data,     # x-variables\n",
    "            log_chef_ready_target,   # y-variable\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n",
    "\n",
    "\n",
    "# OLS p-value x-dataset (log Y)\n",
    "x_train_OLS, x_test_OLS, y_train_OLS, y_test_OLS = train_test_split(\n",
    "            ols_data,         # x-variables\n",
    "            log_chef_ready_target,   # y-variable\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Training Score : 0.7309\n",
      "OLS Testing Score  : 0.7223\n",
      "OLS Train-Test Gap : 0.0086\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a model object\n",
    "lr = LinearRegression()\n",
    "\n",
    "\n",
    "# FITTING to the training data\n",
    "lr_fit = lr.fit(x_train_OLS, y_train_OLS)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "lr_pred = lr_fit.predict(x_test_OLS)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('OLS Training Score :', lr.score(x_train_OLS, y_train_OLS).round(4))\n",
    "print('OLS Testing Score  :', lr.score(x_test_OLS, y_test_OLS).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lr_train_score = lr.score(x_train_OLS, y_train_OLS).round(4) # using R-square\n",
    "lr_test_score  = lr.score(x_test_OLS, y_test_OLS).round(4)   # using R-square\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('OLS Train-Test Gap :', abs(lr_train_score - lr_test_score).round(4))\n",
    "lr_test_gap = abs(lr_train_score - lr_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('intercept', 1.45)\n",
      "('CROSS_SELL_SUCCESS', -0.02)\n",
      "('PRODUCT_CATEGORIES_VIEWED', 0.0)\n",
      "('TASTES_AND_PREFERENCES', 0.01)\n",
      "('MEDIAN_MEAL_RATING', 0.06)\n",
      "('TOTAL_PHOTOS_VIEWED', 0.0)\n",
      "('yahoo', 0.03)\n",
      "('log_AVG_PREP_VID_TIME', 0.58)\n",
      "('log_TOTAL_MEALS_ORDERED', 0.25)\n",
      "('AVG_ORDER_SIZE', -0.02)\n",
      "('log_UNIQUE_MEALS_PURCH', -0.18)\n",
      "('log_CONTACTS_W_CUSTOMER_SERVICE', 0.11)\n",
      "('has_MASTER_CLASSES_ATTENDED', 0.04)\n",
      "('has_WEEKLY_PLAN', -0.01)\n",
      "('walmart', 0.07)\n"
     ]
    }
   ],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "lr_model_values = zip(chef_ready_data[x_variables].columns,\n",
    "                      lr_fit.coef_.round(decimals = 2))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "lr_model_lst = [('intercept', lr_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in lr_model_values:\n",
    "    lr_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in lr_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('intercept', 1.45)\n",
      "('CROSS_SELL_SUCCESS', -0.02)\n",
      "('PRODUCT_CATEGORIES_VIEWED', 0.0)\n",
      "('TASTES_AND_PREFERENCES', 0.01)\n",
      "('MEDIAN_MEAL_RATING', 0.06)\n",
      "('TOTAL_PHOTOS_VIEWED', 0.0)\n",
      "('yahoo', 0.03)\n",
      "('log_AVG_PREP_VID_TIME', 0.58)\n",
      "('log_TOTAL_MEALS_ORDERED', 0.25)\n",
      "('AVG_ORDER_SIZE', -0.02)\n",
      "('log_UNIQUE_MEALS_PURCH', -0.18)\n",
      "('log_CONTACTS_W_CUSTOMER_SERVICE', 0.11)\n",
      "('has_MASTER_CLASSES_ATTENDED', 0.04)\n",
      "('has_WEEKLY_PLAN', -0.01)\n",
      "('walmart', 0.07)\n"
     ]
    }
   ],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "lr_model_values = zip(chef_ready_data[x_variables].columns,\n",
    "                      lr_fit.coef_.round(decimals = 2))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "lr_model_lst = [('intercept', lr_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in lr_model_values:\n",
    "    lr_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in lr_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"girk\">LASSO MODEL</span>(<span class=\"burk\">this is the final model</span>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Training Score : 0.7684\n",
      "Lasso Testing Score  : 0.7648\n",
      "Lasso Train-Test Gap : 0.0036\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# INSTANTIATING a model object\n",
    "import sklearn.linear_model # linear models\n",
    "lasso_model = sklearn.linear_model.Lasso(alpha     = 0.0005,  # changed alpha to 0.0005\n",
    "                                         normalize = False) # change magitude to false\n",
    "\n",
    "\n",
    "# FITTING to the training data\n",
    "lasso_fit = lasso_model.fit(x_train_FULL, y_train_FULL)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "lasso_pred = lasso_fit.predict(x_test_FULL)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Lasso Training Score :', lasso_model.score(x_train_FULL, y_train_FULL).round(4))\n",
    "print('Lasso Testing Score  :', lasso_model.score(x_test_FULL, y_test_FULL).round(4))\n",
    "\n",
    "\n",
    "## the following code has been provided for you ##\n",
    "\n",
    "# saving scoring data for future use\n",
    "lasso_train_score = lasso_model.score(x_train_FULL, y_train_FULL).round(4) # using R-square\n",
    "lasso_test_score  = lasso_model.score(x_test_FULL, y_test_FULL).round(4)   # using R-square\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('Lasso Train-Test Gap :', abs(lasso_train_score - lasso_test_score).round(4))\n",
    "lasso_test_gap = abs(lasso_train_score - lasso_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('intercept', 2.43086)\n",
      "('CROSS_SELL_SUCCESS', -0.01411)\n",
      "('TOTAL_MEALS_ORDERED', -0.00072)\n",
      "('UNIQUE_MEALS_PURCH', 0.04453)\n",
      "('CONTACTS_W_CUSTOMER_SERVICE', 0.00851)\n",
      "('PRODUCT_CATEGORIES_VIEWED', 0.00216)\n",
      "('AVG_TIME_PER_SITE_VISIT', 1e-05)\n",
      "('MOBILE_NUMBER', 0.00093)\n",
      "('CANCELLATIONS_BEFORE_NOON', 0.00175)\n",
      "('CANCELLATIONS_AFTER_NOON', -0.0008)\n",
      "('TASTES_AND_PREFERENCES', 0.00819)\n",
      "('PC_LOGINS', -0.00053)\n",
      "('MOBILE_LOGINS', -0.00619)\n",
      "('WEEKLY_PLAN', 0.00017)\n",
      "('EARLY_DELIVERIES', -0.00122)\n",
      "('LATE_DELIVERIES', -0.0005)\n",
      "('PACKAGE_LOCKER', -0.00873)\n",
      "('REFRIGERATED_LOCKER', -0.00494)\n",
      "('AVG_PREP_VID_TIME', 0.00142)\n",
      "('AVG_ORDER_SIZE', -0.0115)\n",
      "('MASTER_CLASSES_ATTENDED', 0.00309)\n",
      "('MEDIAN_MEAL_RATING', 0.05391)\n",
      "('AVG_CLICKS_PER_VISIT', -0.00349)\n",
      "('TOTAL_PHOTOS_VIEWED', 7e-05)\n",
      "('EMAIL_type', -0.0)\n",
      "('amex', 0.0)\n",
      "('aol', 0.0)\n",
      "('apple', -0.0)\n",
      "('boeing', 0.0)\n",
      "('caterpillar', 0.0)\n",
      "('chevron', -0.0)\n",
      "('cisco', 0.0)\n",
      "('cocacola', 0.0)\n",
      "('disney', -0.0)\n",
      "('dupont', 0.0)\n",
      "('exxon', 0.0)\n",
      "('ge', -0.0)\n",
      "('gmail', 0.0)\n",
      "('goldmansacs', 0.0)\n",
      "('homedepot', -0.0)\n",
      "('hotmail', -0.0)\n",
      "('ibm', 0.0)\n",
      "('intel', 0.0)\n",
      "('jnj', -0.0)\n",
      "('jpmorgan', 0.0)\n",
      "('live', 0.0)\n",
      "('mcdonalds', 0.0)\n",
      "('me', -0.0)\n",
      "('merck', -0.0)\n",
      "('microsoft', -0.0)\n",
      "('mmm', 0.0)\n",
      "('msn', -0.0)\n",
      "('nike', 0.0)\n",
      "('passport', 0.0)\n",
      "('pfizer', 0.0)\n",
      "('pg', 0.0)\n",
      "('protonmail', -0.00468)\n",
      "('travelers', -0.0)\n",
      "('unitedhealth', 0.0)\n",
      "('unitedtech', -0.0)\n",
      "('verizon', -0.00586)\n",
      "('visa', -0.0)\n",
      "('walmart', 0.00556)\n",
      "('yahoo', 0.01404)\n",
      "('log_AVG_ORDER_SIZE', 0.0)\n",
      "('log_AVG_TIME_PER_SITE_VISIT', 0.0)\n",
      "('log_AVG_PREP_VID_TIME', 0.0)\n",
      "('log_TOTAL_MEALS_ORDERED', 0.38117)\n",
      "('log_UNIQUE_MEALS_PURCH', -0.54879)\n",
      "('log_CONTACTS_W_CUSTOMER_SERVICE', 0.0)\n",
      "('log_PRODUCT_CATEGORIES_VIEWED', -0.01057)\n",
      "('log_AVG_CLICKS_PER_VISIT', -0.0)\n",
      "('has_WEEKLY_PLAN', -0.01306)\n",
      "('has_VIEWED_PHOTOS', 0.01765)\n",
      "('has_EARLY_DELIVERIES', -0.0)\n",
      "('has_LATE_DELIVERIES', 0.0)\n",
      "('has_MASTER_CLASSES_ATTENDED', 0.03552)\n"
     ]
    }
   ],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "lasso_model_values = zip(chef_ready_data.columns, lasso_fit.coef_.round(decimals = 5))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "lasso_model_lst = [('intercept', lasso_fit.intercept_.round(decimals = 5))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in lasso_model_values:\n",
    "    lasso_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in lasso_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('intercept', 2.43086)\n",
      "('CROSS_SELL_SUCCESS', -0.01411)\n",
      "('TOTAL_MEALS_ORDERED', -0.00072)\n",
      "('UNIQUE_MEALS_PURCH', 0.04453)\n",
      "('CONTACTS_W_CUSTOMER_SERVICE', 0.00851)\n",
      "('PRODUCT_CATEGORIES_VIEWED', 0.00216)\n",
      "('AVG_TIME_PER_SITE_VISIT', 1e-05)\n",
      "('MOBILE_NUMBER', 0.00093)\n",
      "('CANCELLATIONS_BEFORE_NOON', 0.00175)\n",
      "('CANCELLATIONS_AFTER_NOON', -0.0008)\n",
      "('TASTES_AND_PREFERENCES', 0.00819)\n",
      "('PC_LOGINS', -0.00053)\n",
      "('MOBILE_LOGINS', -0.00619)\n",
      "('WEEKLY_PLAN', 0.00017)\n",
      "('EARLY_DELIVERIES', -0.00122)\n",
      "('LATE_DELIVERIES', -0.0005)\n",
      "('PACKAGE_LOCKER', -0.00873)\n",
      "('REFRIGERATED_LOCKER', -0.00494)\n",
      "('AVG_PREP_VID_TIME', 0.00142)\n",
      "('AVG_ORDER_SIZE', -0.0115)\n",
      "('MASTER_CLASSES_ATTENDED', 0.00309)\n",
      "('MEDIAN_MEAL_RATING', 0.05391)\n",
      "('AVG_CLICKS_PER_VISIT', -0.00349)\n",
      "('TOTAL_PHOTOS_VIEWED', 7e-05)\n",
      "('amex', 0.0)\n",
      "('apple', -0.0)\n",
      "('caterpillar', 0.0)\n",
      "('cisco', 0.0)\n",
      "('disney', -0.0)\n",
      "('exxon', 0.0)\n",
      "('gmail', 0.0)\n",
      "('homedepot', -0.0)\n",
      "('ibm', 0.0)\n",
      "('jnj', -0.0)\n",
      "('live', 0.0)\n",
      "('me', -0.0)\n",
      "('microsoft', -0.0)\n",
      "('msn', -0.0)\n",
      "('passport', 0.0)\n",
      "('pg', 0.0)\n",
      "('protonmail', -0.00468)\n",
      "('unitedhealth', 0.0)\n",
      "('verizon', -0.00586)\n",
      "('walmart', 0.00556)\n",
      "('yahoo', 0.01404)\n",
      "('log_AVG_TIME_PER_SITE_VISIT', 0.0)\n",
      "('log_TOTAL_MEALS_ORDERED', 0.38117)\n",
      "('log_UNIQUE_MEALS_PURCH', -0.54879)\n",
      "('log_PRODUCT_CATEGORIES_VIEWED', -0.01057)\n",
      "('has_WEEKLY_PLAN', -0.01306)\n",
      "('has_VIEWED_PHOTOS', 0.01765)\n",
      "('has_LATE_DELIVERIES', 0.0)\n",
      "('has_MASTER_CLASSES_ATTENDED', 0.03552)\n"
     ]
    }
   ],
   "source": [
    "## This code may have to be run more than once ##\n",
    "\n",
    "# dropping coefficients that are equal to zero\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for feature, coefficient in lasso_model_lst:\n",
    "        \n",
    "        if coefficient == 0:\n",
    "            lasso_model_lst.remove((feature, coefficient))\n",
    "\n",
    "            \n",
    "# checking the results\n",
    "for pair in lasso_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"girk\">ARD MODEL</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.767\n",
      "Testing Score : 0.7587\n",
      "ARD Train-Test Gap : 0.0083\n"
     ]
    }
   ],
   "source": [
    "#ARD MODEL\n",
    "# INSTANTIATING a model object\n",
    "ard_model = sklearn.linear_model.ARDRegression(normalize  = False)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "ard_fit = ard_model.fit(x_train_FULL, y_train_FULL)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "ard_pred = ard_fit.predict(x_test_FULL)\n",
    "\n",
    "\n",
    "print('Training Score:', ard_model.score(x_train_FULL, y_train_FULL).round(4))\n",
    "print('Testing Score :',  ard_model.score(x_test_FULL, y_test_FULL).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "ard_train_score = ard_model.score(x_train_FULL, y_train_FULL).round(4)\n",
    "ard_test_score  = ard_model.score(x_test_FULL, y_test_FULL).round(4)\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('ARD Train-Test Gap :', abs(ard_train_score - ard_test_score).round(4))\n",
    "ard_test_gap = abs(ard_train_score - ard_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('intercept', 1.89)\n",
      "('CROSS_SELL_SUCCESS', -0.01223)\n",
      "('TOTAL_MEALS_ORDERED', 0.0)\n",
      "('UNIQUE_MEALS_PURCH', 0.0482)\n",
      "('CONTACTS_W_CUSTOMER_SERVICE', 0.0)\n",
      "('PRODUCT_CATEGORIES_VIEWED', 0.0)\n",
      "('AVG_TIME_PER_SITE_VISIT', 0.0)\n",
      "('MOBILE_NUMBER', 0.0)\n",
      "('CANCELLATIONS_BEFORE_NOON', 0.0)\n",
      "('CANCELLATIONS_AFTER_NOON', 0.0)\n",
      "('TASTES_AND_PREFERENCES', 0.0)\n",
      "('PC_LOGINS', 0.0)\n",
      "('MOBILE_LOGINS', 0.0)\n",
      "('WEEKLY_PLAN', 0.0)\n",
      "('EARLY_DELIVERIES', 0.0)\n",
      "('LATE_DELIVERIES', 0.0)\n",
      "('PACKAGE_LOCKER', 0.0)\n",
      "('REFRIGERATED_LOCKER', 0.0)\n",
      "('AVG_PREP_VID_TIME', 0.0)\n",
      "('AVG_ORDER_SIZE', -0.01556)\n",
      "('MASTER_CLASSES_ATTENDED', 0.0)\n",
      "('MEDIAN_MEAL_RATING', 0.05497)\n",
      "('AVG_CLICKS_PER_VISIT', 0.01553)\n",
      "('TOTAL_PHOTOS_VIEWED', 0.0)\n",
      "('EMAIL_type', 0.0)\n",
      "('amex', 0.0)\n",
      "('aol', 0.0)\n",
      "('apple', 0.0)\n",
      "('boeing', 0.00567)\n",
      "('caterpillar', 0.0)\n",
      "('chevron', 0.0)\n",
      "('cisco', 0.00491)\n",
      "('cocacola', 0.0)\n",
      "('disney', 0.0)\n",
      "('dupont', 0.0)\n",
      "('exxon', 0.0)\n",
      "('ge', 0.0)\n",
      "('gmail', 0.0)\n",
      "('goldmansacs', 0.0)\n",
      "('homedepot', 0.0)\n",
      "('hotmail', 0.0)\n",
      "('ibm', 0.0)\n",
      "('intel', 0.0)\n",
      "('jnj', 0.0)\n",
      "('jpmorgan', 0.0)\n",
      "('live', 0.0)\n",
      "('mcdonalds', 0.0)\n",
      "('me', 0.0)\n",
      "('merck', -0.01789)\n",
      "('microsoft', -0.01888)\n",
      "('mmm', 0.0)\n",
      "('msn', 0.0)\n",
      "('nike', 0.0)\n",
      "('passport', 0.0)\n",
      "('pfizer', 0.0)\n",
      "('pg', 0.0)\n",
      "('protonmail', 0.0)\n",
      "('travelers', 0.0)\n",
      "('unitedhealth', 0.0)\n",
      "('unitedtech', 0.0)\n",
      "('verizon', -0.04164)\n",
      "('visa', 0.0)\n",
      "('walmart', 0.03622)\n",
      "('yahoo', 0.01757)\n",
      "('log_AVG_ORDER_SIZE', 0.0)\n",
      "('log_AVG_TIME_PER_SITE_VISIT', 0.01021)\n",
      "('log_AVG_PREP_VID_TIME', 0.5824)\n",
      "('log_TOTAL_MEALS_ORDERED', 0.25829)\n",
      "('log_UNIQUE_MEALS_PURCH', -0.59713)\n",
      "('log_CONTACTS_W_CUSTOMER_SERVICE', 0.10465)\n",
      "('log_PRODUCT_CATEGORIES_VIEWED', 0.0)\n",
      "('log_AVG_CLICKS_PER_VISIT', -0.54967)\n",
      "('has_WEEKLY_PLAN', -0.01011)\n",
      "('has_VIEWED_PHOTOS', 0.03121)\n",
      "('has_EARLY_DELIVERIES', 0.0)\n",
      "('has_LATE_DELIVERIES', 0.0)\n",
      "('has_MASTER_CLASSES_ATTENDED', 0.03732)\n"
     ]
    }
   ],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "ard_model_values = zip(chef_ready_data.columns, ard_fit.coef_.round(decimals = 5))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "ard_model_lst = [('intercept', ard_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in ard_model_values:\n",
    "    ard_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in ard_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('intercept', 1.89)\n",
      "('CROSS_SELL_SUCCESS', -0.01223)\n",
      "('UNIQUE_MEALS_PURCH', 0.0482)\n",
      "('PRODUCT_CATEGORIES_VIEWED', 0.0)\n",
      "('MOBILE_NUMBER', 0.0)\n",
      "('CANCELLATIONS_AFTER_NOON', 0.0)\n",
      "('PC_LOGINS', 0.0)\n",
      "('WEEKLY_PLAN', 0.0)\n",
      "('LATE_DELIVERIES', 0.0)\n",
      "('REFRIGERATED_LOCKER', 0.0)\n",
      "('AVG_ORDER_SIZE', -0.01556)\n",
      "('MEDIAN_MEAL_RATING', 0.05497)\n",
      "('AVG_CLICKS_PER_VISIT', 0.01553)\n",
      "('EMAIL_type', 0.0)\n",
      "('aol', 0.0)\n",
      "('boeing', 0.00567)\n",
      "('chevron', 0.0)\n",
      "('cisco', 0.00491)\n",
      "('disney', 0.0)\n",
      "('exxon', 0.0)\n",
      "('gmail', 0.0)\n",
      "('homedepot', 0.0)\n",
      "('ibm', 0.0)\n",
      "('jnj', 0.0)\n",
      "('live', 0.0)\n",
      "('me', 0.0)\n",
      "('merck', -0.01789)\n",
      "('microsoft', -0.01888)\n",
      "('msn', 0.0)\n",
      "('passport', 0.0)\n",
      "('pg', 0.0)\n",
      "('travelers', 0.0)\n",
      "('unitedtech', 0.0)\n",
      "('verizon', -0.04164)\n",
      "('walmart', 0.03622)\n",
      "('yahoo', 0.01757)\n",
      "('log_AVG_TIME_PER_SITE_VISIT', 0.01021)\n",
      "('log_AVG_PREP_VID_TIME', 0.5824)\n",
      "('log_TOTAL_MEALS_ORDERED', 0.25829)\n",
      "('log_UNIQUE_MEALS_PURCH', -0.59713)\n",
      "('log_CONTACTS_W_CUSTOMER_SERVICE', 0.10465)\n",
      "('log_AVG_CLICKS_PER_VISIT', -0.54967)\n",
      "('has_WEEKLY_PLAN', -0.01011)\n",
      "('has_VIEWED_PHOTOS', 0.03121)\n",
      "('has_LATE_DELIVERIES', 0.0)\n",
      "('has_MASTER_CLASSES_ATTENDED', 0.03732)\n"
     ]
    }
   ],
   "source": [
    "## This code may have to be run more than once ##\n",
    "\n",
    "# dropping coefficients that are equal to zero\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for feature, coefficient in ard_model_lst:\n",
    "        \n",
    "        if coefficient == 0:\n",
    "            ard_model_lst.remove((feature, coefficient))\n",
    "\n",
    "            \n",
    "# checking the results\n",
    "for pair in ard_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"girk\">Comparing results</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model      Train Score      Test Score         Train-Test Gap        Model Size\n",
      "-----      -----------      ----------         --------------        ----------\n",
      "OLS        0.7309            0.7223               0.0086                15\n",
      "Lasso      0.7684            0.7648               0.0036                53\n",
      "ARD        0.767             0.7587               0.0083                46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comparing results\n",
    "\n",
    "print(f\"\"\"\n",
    "Model      Train Score      Test Score         Train-Test Gap        Model Size\n",
    "-----      -----------      ----------         --------------        ----------\n",
    "OLS        {lr_train_score}            {lr_test_score}               {lr_test_gap}                {len(lr_model_lst)}\n",
    "Lasso      {lasso_train_score}            {lasso_test_score}               {lasso_test_gap}                {len(lasso_model_lst)}\n",
    "ARD        {ard_train_score}             {ard_test_score}               {ard_test_gap}                {len(ard_model_lst)}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Type'    : ['OLS', 'Lasso', 'ARD'],\n",
    "           \n",
    "    'Training' : [lr_train_score, lasso_train_score,\n",
    "                 ard_train_score],\n",
    "           \n",
    "    'Testing'  : [lr_test_score, lasso_test_score,\n",
    "                ard_test_score],\n",
    "                    \n",
    "    'Train-Test Gap' : [lr_test_gap, lasso_test_gap,\n",
    "                        ard_test_gap],\n",
    "                    \n",
    "    'Model Size' : [len(lr_model_lst), len(lasso_model_lst),\n",
    "                    len(ard_model_lst)],\n",
    "                    \n",
    "    'Model' : [lr_model_lst, lasso_model_lst, ard_model_lst]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)\n",
    "\n",
    "\n",
    "# sending model results to Excel\n",
    "model_performance.to_excel('./log_revenue_chef_ready_linear_model_performance.xlsx',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "prediction_results = pd.DataFrame(data = {\n",
    "    'Original log_Revenue' : y_test_FULL,\n",
    "    'LR Predictions'       : lr_pred.round(decimals = 5),\n",
    "    'Lasso Predictions'    : lasso_pred.round(decimals = 5),\n",
    "    'ARD Predictions'      : ard_pred.round(decimals = 5),\n",
    "    'LR Deviation'         : lr_pred.round(decimals = 5) - y_test_FULL,\n",
    "    'Lasso Deviation'      : lasso_pred.round(decimals = 5) - y_test_FULL,\n",
    "    'ARD Deviation'        : ard_pred.round(decimals = 5) - y_test_FULL,\n",
    "    })\n",
    "\n",
    "\n",
    "prediction_results.to_excel(excel_writer = './log_revenue_chef_ready_linear_model_predictions.xlsx',\n",
    "                            index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
